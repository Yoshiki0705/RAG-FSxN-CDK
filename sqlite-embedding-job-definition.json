{
  "jobDefinitionName": "sqlite-embedding-batch-job-def",
  "type": "container",
  "containerProperties": {
    "image": "public.ecr.aws/amazonlinux/amazonlinux:2023",
    "vcpus": 2,
    "memory": 4096,
    "command": [
      "sh",
      "-c",
      "echo 'Starting SQLite Embedding Batch Job...' && yum update -y && yum install -y nfs-utils python3 python3-pip && echo 'Installing Python dependencies...' && pip3 install boto3 numpy && echo 'Creating mount point...' && mkdir -p /mnt/fsx-sqlite && echo 'Mounting FSx for ONTAP sqlite-load-test volume...' && mount -t nfs -o nfsvers=3 ${SVM_NFS_ENDPOINT}:${VOLUME_PATH} /mnt/fsx-sqlite && echo 'Mount successful!' && df -h /mnt/fsx-sqlite && ls -la /mnt/fsx-sqlite && echo 'Creating embedding processing script...' && cat > /tmp/embedding_processor.py << 'EOF'\nimport os\nimport json\nimport boto3\nimport time\nfrom datetime import datetime\n\ndef process_sqlite_files():\n    \"\"\"SQLiteファイルからEmbedding処理を実行\"\"\"\n    bedrock = boto3.client('bedrock-runtime', region_name=os.environ.get('AWS_DEFAULT_REGION', 'ap-northeast-1'))\n    \n    # SQLiteファイルを検索\n    sqlite_dir = '/mnt/fsx-sqlite'\n    sqlite_files = []\n    \n    for root, dirs, files in os.walk(sqlite_dir):\n        for file in files:\n            if file.endswith('.db'):\n                sqlite_files.append(os.path.join(root, file))\n    \n    print(f'Found {len(sqlite_files)} SQLite files for processing')\n    \n    # 各SQLiteファイルに対してEmbedding処理をシミュレート\n    for sqlite_file in sqlite_files:\n        print(f'Processing: {sqlite_file}')\n        \n        # ファイル情報を取得\n        file_stat = os.stat(sqlite_file)\n        file_size = file_stat.st_size\n        \n        # Embedding処理のシミュレート（実際のBedrockは使用せず、メタデータのみ作成）\n        embedding_metadata = {\n            'file_path': sqlite_file,\n            'file_size': file_size,\n            'processed_at': datetime.now().isoformat(),\n            'embedding_model': 'amazon.titan-embed-text-v1',\n            'status': 'processed',\n            'chunk_count': max(1, file_size // 1024)  # 1KBあたり1チャンク\n        }\n        \n        # メタデータファイルを作成\n        metadata_file = sqlite_file + '.embedding_metadata.json'\n        with open(metadata_file, 'w') as f:\n            json.dump(embedding_metadata, f, indent=2)\n        \n        print(f'Created embedding metadata: {metadata_file}')\n        \n        # 処理時間をシミュレート\n        time.sleep(1)\n    \n    return len(sqlite_files)\n\nif __name__ == '__main__':\n    try:\n        processed_count = process_sqlite_files()\n        print(f'Successfully processed {processed_count} SQLite files')\n    except Exception as e:\n        print(f'Error processing SQLite files: {e}')\n        exit(1)\nEOF\necho 'Running embedding processing...' && python3 /tmp/embedding_processor.py && echo 'Listing processed files...' && find /mnt/fsx-sqlite -name '*.embedding_metadata.json' -exec ls -la {} \\; && echo 'SQLite Embedding Batch Job completed successfully!'"
    ],
    "environment": [
      {
        "name": "FSX_ID",
        "value": "fs-0efd9429aa9ba839a"
      },
      {
        "name": "AWS_DEFAULT_REGION",
        "value": "ap-northeast-1"
      },
      {
        "name": "VOLUME_PATH",
        "value": "/sqlite-load-test"
      },
      {
        "name": "SVM_NFS_ENDPOINT",
        "value": "svm-01b48eb910be1c588.fs-0efd9429aa9ba839a.fsx.ap-northeast-1.amazonaws.com"
      },
      {
        "name": "BEDROCK_MODEL_ID",
        "value": "amazon.titan-embed-text-v1"
      }
    ],
    "privileged": false
  },
  "retryStrategy": {
    "attempts": 3
  },
  "timeout": {
    "attemptDurationSeconds": 3600
  }
}