/**
 * ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
 * 
 * ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¿œç­”æ©Ÿèƒ½ã‚’æ¤œè¨¼
 * å®Ÿæœ¬ç•ªAmazon Bedrockã§ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ€§èƒ½ã‚’ãƒ†ã‚¹ãƒˆ
 * 
 * @version 1.0.0
 * @author NetApp Japan Technology Team
 */

import {
  BedrockRuntimeClient,
  InvokeModelWithResponseStreamCommand
} from '@aws-sdk/client-bedrock-runtime';

import { ProductionConfig } from '../../config/production-config';
import { TestResult, TestExecutionStatus } from '../../core/production-test-engine';

/**
 * ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ†ã‚¹ãƒˆçµæœ
 */
export interface StreamingTestResult extends TestResult {
  streamingMetrics?: {
    firstTokenLatency: number;
    averageTokenLatency: number;
    totalTokens: number;
    streamDuration: number;
    throughput: number;
  };
  qualityMetrics?: {
    streamStability: number;
    contentCoherence: number;
    realTimeScore: number;
  };
}

/**
 * ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
 */
export interface StreamingTestCase {
  id: string;
  name: string;
  prompt: string;
  expectedTokens: number;
  maxLatency: number;
  modelId: string;
}

/**
 * ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
 */
export class StreamingResponseTestModule {
  private config: ProductionConfig;
  private bedrockClient: BedrockRuntimeClient;
  private testCases: StreamingTestCase[];

  constructor(config: ProductionConfig) {
    this.config = config;
    
    this.bedrockClient = new BedrockRuntimeClient({
      region: config.region,
      credentials: { profile: config.awsProfile }
    });
    
    this.testCases = this.loadStreamingTestCases();
  }

  /**
   * ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã®èª­ã¿è¾¼ã¿
   */
  private loadStreamingTestCases(): StreamingTestCase[] {
    return [
      {
        id: 'stream-short-001',
        name: 'çŸ­æ–‡ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ†ã‚¹ãƒˆ',
        prompt: 'RAGã‚·ã‚¹ãƒ†ãƒ ã«ã¤ã„ã¦ç°¡æ½”ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚',
        expectedTokens: 100,
        maxLatency: 500,
        modelId: 'amazon.nova-lite-v1:0'
      },
      {
        id: 'stream-medium-001',
        name: 'ä¸­æ–‡ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ†ã‚¹ãƒˆ',
        prompt: 'Amazon FSx for NetApp ONTAPã¨Amazon Bedrockã‚’çµ„ã¿åˆã‚ã›ãŸRAGã‚·ã‚¹ãƒ†ãƒ ã®æŠ€è¡“çš„åˆ©ç‚¹ã«ã¤ã„ã¦è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚',
        expectedTokens: 300,
        maxLatency: 800,
        modelId: 'amazon.nova-pro-v1:0'
      },
      {
        id: 'stream-long-001',
        name: 'é•·æ–‡ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ†ã‚¹ãƒˆ',
        prompt: 'ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºç’°å¢ƒã«ãŠã‘ã‚‹æ¨©é™èªè­˜å‹RAGã‚·ã‚¹ãƒ†ãƒ ã®è¨­è¨ˆåŸå‰‡ã€å®Ÿè£…æ–¹æ³•ã€é‹ç”¨ä¸Šã®è€ƒæ…®äº‹é …ã«ã¤ã„ã¦ã€å…·ä½“ä¾‹ã‚’äº¤ãˆãªãŒã‚‰åŒ…æ‹¬çš„ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚',
        expectedTokens: 500,
        maxLatency: 1200,
        modelId: 'amazon.nova-pro-v1:0'
      },
      {
        id: 'stream-realtime-001',
        name: 'ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¿œç­”ãƒ†ã‚¹ãƒˆ',
        prompt: 'ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã§ã‚ˆãã‚ã‚‹è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ï¼šã€Œã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ã©ã®ã‚ˆã†ã«å‹•ä½œã—ã¾ã™ã‹ï¼Ÿã€',
        expectedTokens: 150,
        maxLatency: 300,
        modelId: 'amazon.nova-micro-v1:0'
      }
    ];
  }

  /**
   * åŒ…æ‹¬çš„ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ†ã‚¹ãƒˆ
   */
  async testComprehensiveStreaming(): Promise<StreamingTestResult> {
    const testId = 'streaming-comprehensive-001';
    const startTime = Date.now();
    
    console.log('ğŸ“¡ åŒ…æ‹¬çš„ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹...');

    try {
      const results: any[] = [];

      // å„ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’å®Ÿè¡Œ
      for (const testCase of this.testCases) {
        console.log(`   ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­: ${testCase.name}`);
        
        const caseResult = await this.executeStreamingTest(testCase);
        results.push(caseResult);
      }

      // ç·åˆãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—
      const aggregatedMetrics = this.aggregateStreamingMetrics(results);
      const qualityMetrics = this.evaluateStreamingQuality(results);

      const success = aggregatedMetrics.firstTokenLatency < 500 && 
                     qualityMetrics.realTimeScore > 0.8;

      const result: StreamingTestResult = {
        testId,
        testName: 'åŒ…æ‹¬çš„ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ†ã‚¹ãƒˆ',
        category: 'streaming',
        status: success ? TestExecutionStatus.COMPLETED : TestExecutionStatus.FAILED,
        startTime: new Date(startTime),
        endTime: new Date(),
        duration: Date.now() - startTime,
        success,
        streamingMetrics: aggregatedMetrics,
        qualityMetrics,
        metadata: {
          testCaseCount: this.testCases.length,
          testResults: results
        }
      };

      if (success) {
        console.log('âœ… åŒ…æ‹¬çš„ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ†ã‚¹ãƒˆæˆåŠŸ');
      } else {
        console.error('âŒ åŒ…æ‹¬çš„ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ†ã‚¹ãƒˆå¤±æ•—');
      }

      return result;

    } catch (error) {
      console.error('âŒ åŒ…æ‹¬çš„ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼:', error);
      
      return {
        testId,
        testName: 'åŒ…æ‹¬çš„ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ†ã‚¹ãƒˆ',
        category: 'streaming',
        status: TestExecutionStatus.FAILED,
        startTime: new Date(startTime),
        endTime: new Date(),
        duration: Date.now() - startTime,
        success: false,
        error: error instanceof Error ? error.message : String(error)
      };
    }
  }

  /**
   * å€‹åˆ¥ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ
   */
  private async executeStreamingTest(testCase: StreamingTestCase): Promise<{
    testCase: StreamingTestCase;
    metrics: any;
    success: boolean;
  }> {
    try {
      // èª­ã¿å–ã‚Šå°‚ç”¨ãƒ¢ãƒ¼ãƒ‰ã§ã¯æ¨¡æ“¬çµæœã‚’è¿”ã™
      if (this.config.readOnlyMode) {
        return this.generateMockStreamingResult(testCase);
      }

      // å®Ÿéš›ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ¨è«–
      const streamingResult = await this.performStreamingInference(testCase);
      
      const success = streamingResult.firstTokenLatency <= testCase.maxLatency;

      return {
        testCase,
        metrics: streamingResult,
        success
      };

    } catch (error) {
      console.error(`âŒ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼ (${testCase.id}):`, error);
      return {
        testCase,
        metrics: null,
        success: false
      };
    }
  }

  /**
   * ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ¨è«–å®Ÿè¡Œ
   */
  private async performStreamingInference(testCase: StreamingTestCase): Promise<{
    firstTokenLatency: number;
    averageTokenLatency: number;
    totalTokens: number;
    streamDuration: number;
    throughput: number;
    tokens: string[];
  }> {
    const startTime = Date.now();
    let firstTokenTime: number | null = null;
    const tokenTimes: number[] = [];
    const tokens: string[] = [];

    const requestBody = {
      inputText: testCase.prompt,
      textGenerationConfig: {
        maxTokenCount: testCase.expectedTokens * 2,
        temperature: 0.7,
        topP: 0.9
      }
    };

    const command = new InvokeModelWithResponseStreamCommand({
      modelId: testCase.modelId,
      contentType: 'application/json',
      accept: 'application/json',
      body: JSON.stringify(requestBody)
    });

    const response = await this.bedrockClient.send(command);
    
    if (response.body) {
      for await (const chunk of response.body) {
        const currentTime = Date.now();
        
        if (chunk.chunk?.bytes) {
          const chunkData = JSON.parse(new TextDecoder().decode(chunk.chunk.bytes));
          
          if (chunkData.outputText) {
            if (firstTokenTime === null) {
              firstTokenTime = currentTime - startTime;
            }
            
            tokenTimes.push(currentTime - startTime);
            tokens.push(chunkData.outputText);
          }
        }
      }
    }

    const endTime = Date.now();
    const streamDuration = endTime - startTime;
    const averageTokenLatency = tokenTimes.length > 0 ? 
      tokenTimes.reduce((sum, time) => sum + time, 0) / tokenTimes.length : 0;
    const throughput = tokens.length / (streamDuration / 1000); // tokens per second

    return {
      firstTokenLatency: firstTokenTime || streamDuration,
      averageTokenLatency,
      totalTokens: tokens.length,
      streamDuration,
      throughput,
      tokens
    };
  }

  /**
   * æ¨¡æ“¬ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°çµæœç”Ÿæˆ
   */
  private generateMockStreamingResult(testCase: StreamingTestCase): {
    testCase: StreamingTestCase;
    metrics: any;
    success: boolean;
  } {
    const mockMetrics = {
      firstTokenLatency: Math.random() * testCase.maxLatency * 0.8, // 80%ä»¥å†…
      averageTokenLatency: Math.random() * 100 + 50,
      totalTokens: testCase.expectedTokens + Math.floor(Math.random() * 50),
      streamDuration: Math.random() * 2000 + 1000,
      throughput: Math.random() * 20 + 10,
      tokens: Array(testCase.expectedTokens).fill('æ¨¡æ“¬ãƒˆãƒ¼ã‚¯ãƒ³')
    };

    return {
      testCase,
      metrics: mockMetrics,
      success: mockMetrics.firstTokenLatency <= testCase.maxLatency
    };
  }

  /**
   * ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¡ãƒˆãƒªã‚¯ã‚¹é›†ç´„
   */
  private aggregateStreamingMetrics(results: any[]): {
    firstTokenLatency: number;
    averageTokenLatency: number;
    totalTokens: number;
    streamDuration: number;
    throughput: number;
  } {
    const validResults = results.filter(r => r.success && r.metrics);
    
    if (validResults.length === 0) {
      return {
        firstTokenLatency: 0,
        averageTokenLatency: 0,
        totalTokens: 0,
        streamDuration: 0,
        throughput: 0
      };
    }

    const avgFirstTokenLatency = validResults.reduce((sum, r) => sum + r.metrics.firstTokenLatency, 0) / validResults.length;
    const avgTokenLatency = validResults.reduce((sum, r) => sum + r.metrics.averageTokenLatency, 0) / validResults.length;
    const totalTokens = validResults.reduce((sum, r) => sum + r.metrics.totalTokens, 0);
    const avgStreamDuration = validResults.reduce((sum, r) => sum + r.metrics.streamDuration, 0) / validResults.length;
    const avgThroughput = validResults.reduce((sum, r) => sum + r.metrics.throughput, 0) / validResults.length;

    return {
      firstTokenLatency: avgFirstTokenLatency,
      averageTokenLatency: avgTokenLatency,
      totalTokens,
      streamDuration: avgStreamDuration,
      throughput: avgThroughput
    };
  }

  /**
   * ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å“è³ªè©•ä¾¡
   */
  private evaluateStreamingQuality(results: any[]): {
    streamStability: number;
    contentCoherence: number;
    realTimeScore: number;
  } {
    const validResults = results.filter(r => r.success && r.metrics);
    
    if (validResults.length === 0) {
      return {
        streamStability: 0,
        contentCoherence: 0,
        realTimeScore: 0
      };
    }

    // ã‚¹ãƒˆãƒªãƒ¼ãƒ å®‰å®šæ€§ï¼ˆãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã®ä¸€è²«æ€§ï¼‰
    const latencies = validResults.map(r => r.metrics.firstTokenLatency);
    const avgLatency = latencies.reduce((sum, l) => sum + l, 0) / latencies.length;
    const latencyVariance = latencies.reduce((sum, l) => sum + Math.pow(l - avgLatency, 2), 0) / latencies.length;
    const streamStability = Math.max(0, 1 - (Math.sqrt(latencyVariance) / avgLatency));

    // ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ä¸€è²«æ€§ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆã®å®‰å®šæ€§ï¼‰
    const throughputs = validResults.map(r => r.metrics.throughput);
    const avgThroughput = throughputs.reduce((sum, t) => sum + t, 0) / throughputs.length;
    const contentCoherence = avgThroughput > 5 ? 0.9 : 0.7; // 5 tokens/secä»¥ä¸Šã§é«˜è©•ä¾¡

    // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¹ã‚³ã‚¢ï¼ˆåˆå›ãƒˆãƒ¼ã‚¯ãƒ³ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ™ãƒ¼ã‚¹ï¼‰
    const realTimeScore = avgLatency < 500 ? 1.0 : (avgLatency < 1000 ? 0.8 : 0.5);

    return {
      streamStability,
      contentCoherence,
      realTimeScore
    };
  }

  /**
   * ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
   */
  async cleanup(): Promise<void> {
    console.log('ğŸ§¹ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­...');
    console.log('âœ… ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†');
  }
}

export default StreamingResponseTestModule;