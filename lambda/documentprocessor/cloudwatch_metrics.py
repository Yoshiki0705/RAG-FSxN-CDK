"""
CloudWatchãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†æ©Ÿèƒ½
Markitdownå‡¦ç†ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€æˆåŠŸç‡ã€ã‚¨ãƒ©ãƒ¼ç‡ã®ç›£è¦–
"""

import json
import logging
import os
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
import boto3
from botocore.exceptions import ClientError
from datetime import datetime, timedelta
import time

logger = logging.getLogger(__name__)

@dataclass
class MetricData:
    """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿"""
    metric_name: str
    value: float
    unit: str
    dimensions: Dict[str, str]
    timestamp: Optional[datetime] = None

class CloudWatchMetricsCollector:
    """CloudWatchãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã‚¯ãƒ©ã‚¹"""
    
    # ã‚¯ãƒ©ã‚¹å®šæ•°
    MAX_METRICS_PER_BATCH = 20
    DEFAULT_REGION = 'us-east-1'
    DEFAULT_NAMESPACE = 'RAG/DocumentProcessor/Markitdown'
    
    def __init__(self, 
                 region: str = None,
                 namespace: str = None,
                 max_retries: int = 3):
        """
        åˆæœŸåŒ–
        
        Args:
            region: AWSãƒªãƒ¼ã‚¸ãƒ§ãƒ³
            namespace: CloudWatchãƒ¡ãƒˆãƒªã‚¯ã‚¹åå‰ç©ºé–“
            max_retries: æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°
        """
        self.region = region or os.environ.get('AWS_REGION') or self.DEFAULT_REGION
        self.namespace = namespace or self.DEFAULT_NAMESPACE
        self.max_retries = max_retries
        
        # CloudWatch ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–ï¼‰
        try:
            self.cloudwatch = boto3.client('cloudwatch', region_name=self.region)
            # æ¥ç¶šãƒ†ã‚¹ãƒˆ
            self.cloudwatch.list_metrics(Namespace=self.namespace, MaxRecords=1)
        except Exception as e:
            logger.error(f"CloudWatchã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            raise ValueError(f"CloudWatchæ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        
        logger.info(f"CloudWatchãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã‚’åˆæœŸåŒ–: namespace={self.namespace}, region={self.region}")
    
    def put_conversion_metrics(self, 
                             file_format: str,
                             processing_method: str,
                             success: bool,
                             processing_time_ms: float,
                             file_size_bytes: int,
                             output_size_bytes: int = 0,
                             quality_score: Optional[float] = None) -> bool:
        """
        å¤‰æ›å‡¦ç†ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’é€ä¿¡
        
        Args:
            file_format: ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼
            processing_method: å‡¦ç†æ–¹æ³•ï¼ˆmarkitdown/langchainï¼‰
            success: æˆåŠŸãƒ•ãƒ©ã‚°
            processing_time_ms: å‡¦ç†æ™‚é–“ï¼ˆãƒŸãƒªç§’ï¼‰
            file_size_bytes: å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º
            output_size_bytes: å‡ºåŠ›ã‚µã‚¤ã‚º
            quality_score: å“è³ªã‚¹ã‚³ã‚¢
            
        Returns:
            bool: é€ä¿¡æˆåŠŸãƒ•ãƒ©ã‚°
        """
        try:
            # å…¥åŠ›å€¤æ¤œè¨¼ã¨ã‚µãƒ‹ã‚¿ã‚¤ã‚º
            if not self._validate_metric_inputs(file_format, processing_method, processing_time_ms, file_size_bytes):
                return False
            
            metrics = []
            
            # åŸºæœ¬ãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ï¼ˆã‚µãƒ‹ã‚¿ã‚¤ã‚ºæ¸ˆã¿ï¼‰
            dimensions = {
                'FileFormat': self._sanitize_dimension_value(file_format),
                'ProcessingMethod': self._sanitize_dimension_value(processing_method),
                'Environment': os.environ.get('ENVIRONMENT', 'prod')
            }
            
            # æˆåŠŸç‡ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            metrics.append(MetricData(
                metric_name='ConversionSuccess',
                value=1.0 if success else 0.0,
                unit='Count',
                dimensions=dimensions
            ))
            
            # å‡¦ç†æ™‚é–“ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            metrics.append(MetricData(
                metric_name='ProcessingTime',
                value=processing_time_ms,
                unit='Milliseconds',
                dimensions=dimensions
            ))
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒ¡ãƒˆãƒªã‚¯ã‚¹
            metrics.append(MetricData(
                metric_name='InputFileSize',
                value=file_size_bytes,
                unit='Bytes',
                dimensions=dimensions
            ))
            
            if output_size_bytes > 0:
                metrics.append(MetricData(
                    metric_name='OutputSize',
                    value=output_size_bytes,
                    unit='Bytes',
                    dimensions=dimensions
                ))
                
                # åœ§ç¸®ç‡ãƒ¡ãƒˆãƒªã‚¯ã‚¹
                compression_ratio = output_size_bytes / file_size_bytes if file_size_bytes > 0 else 0
                metrics.append(MetricData(
                    metric_name='CompressionRatio',
                    value=compression_ratio,
                    unit='None',
                    dimensions=dimensions
                ))
            
            # å“è³ªã‚¹ã‚³ã‚¢ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            if quality_score is not None:
                metrics.append(MetricData(
                    metric_name='QualityScore',
                    value=quality_score,
                    unit='None',
                    dimensions=dimensions
                ))
            
            # ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆãƒã‚¤ãƒˆ/ç§’ï¼‰
            if processing_time_ms > 0:
                throughput = (file_size_bytes * 1000) / processing_time_ms  # ãƒã‚¤ãƒˆ/ç§’
                metrics.append(MetricData(
                    metric_name='ProcessingThroughput',
                    value=throughput,
                    unit='Bytes/Second',
                    dimensions=dimensions
                ))
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹é€ä¿¡
            return self._send_metrics(metrics)
            
        except Exception as e:
            logger.error(f"âŒ å¤‰æ›ãƒ¡ãƒˆãƒªã‚¯ã‚¹é€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def put_embedding_metrics(self,
                            embedding_model: str,
                            total_chunks: int,
                            embedding_time_ms: float,
                            batch_size: int,
                            success_count: int,
                            error_count: int = 0) -> bool:
        """
        åŸ‹ã‚è¾¼ã¿ç”Ÿæˆãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’é€ä¿¡
        
        Args:
            embedding_model: åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«å
            total_chunks: ç·ãƒãƒ£ãƒ³ã‚¯æ•°
            embedding_time_ms: åŸ‹ã‚è¾¼ã¿ç”Ÿæˆæ™‚é–“
            batch_size: ãƒãƒƒãƒã‚µã‚¤ã‚º
            success_count: æˆåŠŸæ•°
            error_count: ã‚¨ãƒ©ãƒ¼æ•°
            
        Returns:
            bool: é€ä¿¡æˆåŠŸãƒ•ãƒ©ã‚°
        """
        try:
            metrics = []
            
            # åŸºæœ¬ãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³
            dimensions = {
                'EmbeddingModel': embedding_model,
                'Environment': os.environ.get('ENVIRONMENT', 'prod')
            }
            
            # åŸ‹ã‚è¾¼ã¿ç”Ÿæˆæ•°ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            metrics.append(MetricData(
                metric_name='EmbeddingsGenerated',
                value=success_count,
                unit='Count',
                dimensions=dimensions
            ))
            
            # ã‚¨ãƒ©ãƒ¼æ•°ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            if error_count > 0:
                metrics.append(MetricData(
                    metric_name='EmbeddingErrors',
                    value=error_count,
                    unit='Count',
                    dimensions=dimensions
                ))
            
            # æˆåŠŸç‡ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            success_rate = (success_count / total_chunks * 100) if total_chunks > 0 else 0
            metrics.append(MetricData(
                metric_name='EmbeddingSuccessRate',
                value=success_rate,
                unit='Percent',
                dimensions=dimensions
            ))
            
            # å‡¦ç†æ™‚é–“ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            metrics.append(MetricData(
                metric_name='EmbeddingProcessingTime',
                value=embedding_time_ms,
                unit='Milliseconds',
                dimensions=dimensions
            ))
            
            # ãƒãƒƒãƒã‚µã‚¤ã‚ºãƒ¡ãƒˆãƒªã‚¯ã‚¹
            metrics.append(MetricData(
                metric_name='EmbeddingBatchSize',
                value=batch_size,
                unit='Count',
                dimensions=dimensions
            ))
            
            # å¹³å‡å‡¦ç†æ™‚é–“ï¼ˆãƒãƒ£ãƒ³ã‚¯ã‚ãŸã‚Šï¼‰
            if success_count > 0:
                avg_time_per_chunk = embedding_time_ms / success_count
                metrics.append(MetricData(
                    metric_name='AvgTimePerEmbedding',
                    value=avg_time_per_chunk,
                    unit='Milliseconds',
                    dimensions=dimensions
                ))
            
            # ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆãƒãƒ£ãƒ³ã‚¯/ç§’ï¼‰
            if embedding_time_ms > 0:
                throughput = (success_count * 1000) / embedding_time_ms
                metrics.append(MetricData(
                    metric_name='EmbeddingThroughput',
                    value=throughput,
                    unit='Count/Second',
                    dimensions=dimensions
                ))
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹é€ä¿¡
            return self._send_metrics(metrics)
            
        except Exception as e:
            logger.error(f"âŒ åŸ‹ã‚è¾¼ã¿ãƒ¡ãƒˆãƒªã‚¯ã‚¹é€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def put_storage_metrics(self,
                          storage_type: str,
                          documents_stored: int,
                          storage_time_ms: float,
                          success: bool,
                          index_name: Optional[str] = None) -> bool:
        """
        ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’é€ä¿¡
        
        Args:
            storage_type: ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚¿ã‚¤ãƒ—ï¼ˆopensearch/dynamodbï¼‰
            documents_stored: æ ¼ç´ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°
            storage_time_ms: æ ¼ç´æ™‚é–“
            success: æˆåŠŸãƒ•ãƒ©ã‚°
            index_name: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å
            
        Returns:
            bool: é€ä¿¡æˆåŠŸãƒ•ãƒ©ã‚°
        """
        try:
            metrics = []
            
            # åŸºæœ¬ãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³
            dimensions = {
                'StorageType': storage_type,
                'Environment': os.environ.get('ENVIRONMENT', 'prod')
            }
            
            if index_name:
                dimensions['IndexName'] = index_name
            
            # æ ¼ç´æˆåŠŸãƒ¡ãƒˆãƒªã‚¯ã‚¹
            metrics.append(MetricData(
                metric_name='StorageSuccess',
                value=1.0 if success else 0.0,
                unit='Count',
                dimensions=dimensions
            ))
            
            # æ ¼ç´ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            metrics.append(MetricData(
                metric_name='DocumentsStored',
                value=documents_stored,
                unit='Count',
                dimensions=dimensions
            ))
            
            # æ ¼ç´æ™‚é–“ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            metrics.append(MetricData(
                metric_name='StorageTime',
                value=storage_time_ms,
                unit='Milliseconds',
                dimensions=dimensions
            ))
            
            # ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ/ç§’ï¼‰
            if storage_time_ms > 0:
                throughput = (documents_stored * 1000) / storage_time_ms
                metrics.append(MetricData(
                    metric_name='StorageThroughput',
                    value=throughput,
                    unit='Count/Second',
                    dimensions=dimensions
                ))
            
            # å¹³å‡æ ¼ç´æ™‚é–“ï¼ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚ãŸã‚Šï¼‰
            if documents_stored > 0:
                avg_time_per_doc = storage_time_ms / documents_stored
                metrics.append(MetricData(
                    metric_name='AvgTimePerDocument',
                    value=avg_time_per_doc,
                    unit='Milliseconds',
                    dimensions=dimensions
                ))
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹é€ä¿¡
            return self._send_metrics(metrics)
            
        except Exception as e:
            logger.error(f"âŒ ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒ¡ãƒˆãƒªã‚¯ã‚¹é€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def put_error_metrics(self,
                        error_type: str,
                        error_code: str,
                        file_format: Optional[str] = None,
                        processing_method: Optional[str] = None) -> bool:
        """
        ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’é€ä¿¡
        
        Args:
            error_type: ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—
            error_code: ã‚¨ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰
            file_format: ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼
            processing_method: å‡¦ç†æ–¹æ³•
            
        Returns:
            bool: é€ä¿¡æˆåŠŸãƒ•ãƒ©ã‚°
        """
        try:
            # åŸºæœ¬ãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³
            dimensions = {
                'ErrorType': error_type,
                'ErrorCode': error_code,
                'Environment': os.environ.get('ENVIRONMENT', 'prod')
            }
            
            if file_format:
                dimensions['FileFormat'] = file_format
            
            if processing_method:
                dimensions['ProcessingMethod'] = processing_method
            
            # ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿãƒ¡ãƒˆãƒªã‚¯ã‚¹
            metric = MetricData(
                metric_name='ProcessingError',
                value=1.0,
                unit='Count',
                dimensions=dimensions
            )
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹é€ä¿¡
            return self._send_metrics([metric])
            
        except Exception as e:
            logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒˆãƒªã‚¯ã‚¹é€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def put_performance_metrics(self,
                              total_files_processed: int,
                              total_processing_time_ms: float,
                              memory_usage_mb: Optional[float] = None,
                              cpu_usage_percent: Optional[float] = None) -> bool:
        """
        ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’é€ä¿¡
        
        Args:
            total_files_processed: å‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«æ•°
            total_processing_time_ms: ç·å‡¦ç†æ™‚é–“
            memory_usage_mb: ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ï¼ˆMBï¼‰
            cpu_usage_percent: CPUä½¿ç”¨ç‡ï¼ˆ%ï¼‰
            
        Returns:
            bool: é€ä¿¡æˆåŠŸãƒ•ãƒ©ã‚°
        """
        try:
            metrics = []
            
            # åŸºæœ¬ãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³
            dimensions = {
                'Environment': os.environ.get('ENVIRONMENT', 'prod'),
                'FunctionName': os.environ.get('AWS_LAMBDA_FUNCTION_NAME', 'document-processor')
            }
            
            # å‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«æ•°ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            metrics.append(MetricData(
                metric_name='FilesProcessed',
                value=total_files_processed,
                unit='Count',
                dimensions=dimensions
            ))
            
            # ç·å‡¦ç†æ™‚é–“ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            metrics.append(MetricData(
                metric_name='TotalProcessingTime',
                value=total_processing_time_ms,
                unit='Milliseconds',
                dimensions=dimensions
            ))
            
            # å¹³å‡å‡¦ç†æ™‚é–“ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            if total_files_processed > 0:
                avg_processing_time = total_processing_time_ms / total_files_processed
                metrics.append(MetricData(
                    metric_name='AvgProcessingTime',
                    value=avg_processing_time,
                    unit='Milliseconds',
                    dimensions=dimensions
                ))
            
            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            if memory_usage_mb is not None:
                metrics.append(MetricData(
                    metric_name='MemoryUsage',
                    value=memory_usage_mb,
                    unit='Megabytes',
                    dimensions=dimensions
                ))
            
            # CPUä½¿ç”¨ç‡ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            if cpu_usage_percent is not None:
                metrics.append(MetricData(
                    metric_name='CPUUsage',
                    value=cpu_usage_percent,
                    unit='Percent',
                    dimensions=dimensions
                ))
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹é€ä¿¡
            return self._send_metrics(metrics)
            
        except Exception as e:
            logger.error(f"âŒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹é€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _send_metrics(self, metrics: List[MetricData]) -> bool:
        """
        ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’CloudWatchã«é€ä¿¡ï¼ˆãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãï¼‰
        
        Args:
            metrics: ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆ
            
        Returns:
            bool: é€ä¿¡æˆåŠŸãƒ•ãƒ©ã‚°
        """
        if not metrics:
            return True
        
        # CloudWatchç”¨ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰
        metric_data = self._build_metric_data(metrics)
        
        # ãƒãƒƒãƒå‡¦ç†ã§é€ä¿¡ï¼ˆãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãï¼‰
        return self._send_metrics_with_retry(metric_data)
    
    def _build_metric_data(self, metrics: List[MetricData]) -> List[Dict[str, Any]]:
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰"""
        metric_data = []
        for metric in metrics:
            data = {
                'MetricName': metric.metric_name,
                'Value': metric.value,
                'Unit': metric.unit,
                'Dimensions': [
                    {'Name': key, 'Value': value}
                    for key, value in metric.dimensions.items()
                ]
            }
            
            if metric.timestamp:
                data['Timestamp'] = metric.timestamp
            
            metric_data.append(data)
        
        return metric_data
    
    def _send_metrics_with_retry(self, metric_data: List[Dict[str, Any]]) -> bool:
        """ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ããƒ¡ãƒˆãƒªã‚¯ã‚¹é€ä¿¡"""
        for i in range(0, len(metric_data), self.MAX_METRICS_PER_BATCH):
            batch = metric_data[i:i + self.MAX_METRICS_PER_BATCH]
            
            for retry in range(self.max_retries):
                try:
                    response = self.cloudwatch.put_metric_data(
                        Namespace=self.namespace,
                        MetricData=batch
                    )
                    
                    logger.info(f"ğŸ“Š CloudWatchãƒ¡ãƒˆãƒªã‚¯ã‚¹é€ä¿¡å®Œäº†: {len(batch)}ãƒ¡ãƒˆãƒªã‚¯ã‚¹")
                    break
                    
                except ClientError as e:
                    error_code = e.response['Error']['Code']
                    
                    if error_code in ['Throttling', 'ThrottlingException']:
                        if retry < self.max_retries - 1:
                            wait_time = (2 ** retry) * 0.1  # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•
                            logger.warning(f"CloudWatchã‚¹ãƒ­ãƒƒãƒˆãƒªãƒ³ã‚°ã€{wait_time}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤")
                            time.sleep(wait_time)
                            continue
                    
                    logger.error(f"âŒ CloudWatch API ã‚¨ãƒ©ãƒ¼ ({error_code}): {e}")
                    return False
                    
                except Exception as e:
                    if retry < self.max_retries - 1:
                        logger.warning(f"ãƒ¡ãƒˆãƒªã‚¯ã‚¹é€ä¿¡ã‚¨ãƒ©ãƒ¼ã€ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™: {e}")
                        time.sleep(0.1 * (retry + 1))
                        continue
                    
                    logger.error(f"âŒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹é€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
                    return False
        
        return True
    
    def get_metrics_statistics(self,
                             metric_name: str,
                             start_time: datetime,
                             end_time: datetime,
                             period: int = 300,
                             statistics: List[str] = None) -> Dict[str, Any]:
        """
        ãƒ¡ãƒˆãƒªã‚¯ã‚¹çµ±è¨ˆã‚’å–å¾—
        
        Args:
            metric_name: ãƒ¡ãƒˆãƒªã‚¯ã‚¹å
            start_time: é–‹å§‹æ™‚é–“
            end_time: çµ‚äº†æ™‚é–“
            period: æœŸé–“ï¼ˆç§’ï¼‰
            statistics: çµ±è¨ˆã‚¿ã‚¤ãƒ—ãƒªã‚¹ãƒˆ
            
        Returns:
            Dict: çµ±è¨ˆãƒ‡ãƒ¼ã‚¿
        """
        try:
            if statistics is None:
                statistics = ['Average', 'Sum', 'Maximum', 'Minimum']
            
            response = self.cloudwatch.get_metric_statistics(
                Namespace=self.namespace,
                MetricName=metric_name,
                StartTime=start_time,
                EndTime=end_time,
                Period=period,
                Statistics=statistics
            )
            
            logger.info(f"ğŸ“ˆ ãƒ¡ãƒˆãƒªã‚¯ã‚¹çµ±è¨ˆå–å¾—å®Œäº†: {metric_name}")
            return {
                'metric_name': metric_name,
                'datapoints': response.get('Datapoints', []),
                'label': response.get('Label', ''),
                'period': period,
                'statistics': statistics
            }
            
        except Exception as e:
            logger.error(f"âŒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹çµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {
                'metric_name': metric_name,
                'datapoints': [],
                'error': str(e)
            }
    
    def create_custom_dashboard(self, dashboard_name: str) -> bool:
        """
        ã‚«ã‚¹ã‚¿ãƒ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’ä½œæˆ
        
        Args:
            dashboard_name: ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰å
            
        Returns:
            bool: ä½œæˆæˆåŠŸãƒ•ãƒ©ã‚°
        """
        try:
            dashboard_body = {
                "widgets": [
                    {
                        "type": "metric",
                        "x": 0,
                        "y": 0,
                        "width": 12,
                        "height": 6,
                        "properties": {
                            "metrics": [
                                [self.namespace, "ConversionSuccess", "ProcessingMethod", "markitdown"],
                                [".", ".", ".", "langchain"]
                            ],
                            "period": 300,
                            "stat": "Sum",
                            "region": self.region,
                            "title": "å¤‰æ›æˆåŠŸæ•°"
                        }
                    },
                    {
                        "type": "metric",
                        "x": 0,
                        "y": 6,
                        "width": 12,
                        "height": 6,
                        "properties": {
                            "metrics": [
                                [self.namespace, "ProcessingTime", "ProcessingMethod", "markitdown"],
                                [".", ".", ".", "langchain"]
                            ],
                            "period": 300,
                            "stat": "Average",
                            "region": self.region,
                            "title": "å¹³å‡å‡¦ç†æ™‚é–“"
                        }
                    },
                    {
                        "type": "metric",
                        "x": 0,
                        "y": 12,
                        "width": 12,
                        "height": 6,
                        "properties": {
                            "metrics": [
                                [self.namespace, "EmbeddingsGenerated"],
                                [self.namespace, "EmbeddingErrors"]
                            ],
                            "period": 300,
                            "stat": "Sum",
                            "region": self.region,
                            "title": "åŸ‹ã‚è¾¼ã¿ç”ŸæˆçŠ¶æ³"
                        }
                    }
                ]
            }
            
            self.cloudwatch.put_dashboard(
                DashboardName=dashboard_name,
                DashboardBody=json.dumps(dashboard_body)
            )
            
            logger.info(f"ğŸ“Š ã‚«ã‚¹ã‚¿ãƒ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ä½œæˆå®Œäº†: {dashboard_name}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            return False


    def _validate_metric_inputs(self, file_format: str, processing_method: str, 
                              processing_time_ms: float, file_size_bytes: int) -> bool:
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹å…¥åŠ›å€¤ã®æ¤œè¨¼"""
        # ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã®æ¤œè¨¼
        if not file_format or len(file_format) > 50:
            logger.error(f"ç„¡åŠ¹ãªãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: {file_format}")
            return False
        
        # å‡¦ç†æ–¹æ³•ã®æ¤œè¨¼
        valid_methods = ['markitdown', 'langchain', 'hybrid']
        if processing_method not in valid_methods:
            logger.error(f"ç„¡åŠ¹ãªå‡¦ç†æ–¹æ³•: {processing_method}")
            return False
        
        # æ•°å€¤ã®æ¤œè¨¼
        if processing_time_ms < 0 or processing_time_ms > 3600000:  # 1æ™‚é–“ä»¥å†…
            logger.error(f"ç„¡åŠ¹ãªå‡¦ç†æ™‚é–“: {processing_time_ms}ms")
            return False
        
        if file_size_bytes < 0 or file_size_bytes > 1073741824:  # 1GBä»¥å†…
            logger.error(f"ç„¡åŠ¹ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size_bytes}bytes")
            return False
        
        return True
    
    def _sanitize_dimension_value(self, value: str) -> str:
        """ãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³å€¤ã®ã‚µãƒ‹ã‚¿ã‚¤ã‚º"""
        if not value:
            return 'unknown'
        
        # ç‰¹æ®Šæ–‡å­—ã®é™¤å»ã¨é•·ã•åˆ¶é™
        import re
        sanitized = re.sub(r'[^\w\-\.]', '_', str(value))
        return sanitized[:255]  # CloudWatchã®åˆ¶é™
    
    def get_health_metrics(self) -> Dict[str, Any]:
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã‚·ã‚¹ãƒ†ãƒ ã®å¥å…¨æ€§æƒ…å ±ã‚’å–å¾—"""
        return {
            'region': self.region,
            'namespace': self.namespace,
            'max_retries': self.max_retries,
            'max_batch_size': self.MAX_METRICS_PER_BATCH,
            'client_status': 'healthy' if self.cloudwatch else 'unhealthy'
        }


def create_cloudwatch_metrics_collector(config: Dict[str, Any]) -> CloudWatchMetricsCollector:
    """
    CloudWatchãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
    
    Args:
        config: è¨­å®šè¾æ›¸
        
    Returns:
        CloudWatchMetricsCollector: ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
    """
    return CloudWatchMetricsCollector(
        region=config.get('region'),
        namespace=config.get('namespace'),
        max_retries=config.get('max_retries', 3)
    )


# ãƒ†ã‚¹ãƒˆç”¨ã®ã‚µãƒ³ãƒ—ãƒ«é–¢æ•°
def test_cloudwatch_metrics():
    """
    CloudWatchãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã®ãƒ†ã‚¹ãƒˆ
    """
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã‚’ãƒ†ã‚¹ãƒˆ
    collector = CloudWatchMetricsCollector()
    
    # å¤‰æ›ãƒ¡ãƒˆãƒªã‚¯ã‚¹é€ä¿¡ãƒ†ã‚¹ãƒˆ
    success = collector.put_conversion_metrics(
        file_format='pdf',
        processing_method='markitdown',
        success=True,
        processing_time_ms=1500.0,
        file_size_bytes=1024000,
        output_size_bytes=2048000,
        quality_score=85.5
    )
    print(f"å¤‰æ›ãƒ¡ãƒˆãƒªã‚¯ã‚¹é€ä¿¡: {success}")
    
    # åŸ‹ã‚è¾¼ã¿ãƒ¡ãƒˆãƒªã‚¯ã‚¹é€ä¿¡ãƒ†ã‚¹ãƒˆ
    success = collector.put_embedding_metrics(
        embedding_model='amazon.titan-embed-text-v1',
        total_chunks=10,
        embedding_time_ms=3000.0,
        batch_size=5,
        success_count=10,
        error_count=0
    )
    print(f"åŸ‹ã‚è¾¼ã¿ãƒ¡ãƒˆãƒªã‚¯ã‚¹é€ä¿¡: {success}")
    
    # ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒ¡ãƒˆãƒªã‚¯ã‚¹é€ä¿¡ãƒ†ã‚¹ãƒˆ
    success = collector.put_storage_metrics(
        storage_type='opensearch',
        documents_stored=10,
        storage_time_ms=500.0,
        success=True,
        index_name='documents'
    )
    print(f"ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒ¡ãƒˆãƒªã‚¯ã‚¹é€ä¿¡: {success}")


if __name__ == "__main__":
    test_cloudwatch_metrics()