"""
Markitdownçµ±åˆæ©Ÿèƒ½ã®çµ±åˆãƒ†ã‚¹ãƒˆ
S3ã‹ã‚‰OpenSearchã¾ã§ã®ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ†ã‚¹ãƒˆ
"""

import json
import os
import sys
import unittest
from unittest.mock import Mock, patch, MagicMock
import boto3
from moto import mock_s3, mock_dynamodb, mock_lambda
import tempfile
import shutil
from datetime import datetime

# ãƒ†ã‚¹ãƒˆç”¨ã®ç’°å¢ƒå¤‰æ•°è¨­å®š
os.environ['MARKITDOWN_ENABLED'] = 'true'
os.environ['MARKITDOWN_ENVIRONMENT'] = 'test'
os.environ['AWS_REGION'] = 'us-east-1'
os.environ['DOCUMENTS_BUCKET'] = 'test-documents-bucket'
os.environ['TEMP_PROCESSING_BUCKET'] = 'test-temp-processing-bucket'
os.environ['METADATA_TABLE'] = 'test-metadata-table'
os.environ['TRACKING_TABLE'] = 'test-tracking-table'

# ãƒ†ã‚¹ãƒˆå¯¾è±¡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from document_processor import lambda_handler, DocumentProcessor

class TestS3ToOpenSearchIntegration(unittest.TestCase):
    """S3ã‹ã‚‰OpenSearchã¾ã§ã®çµ±åˆãƒ†ã‚¹ãƒˆ"""
    
    @mock_s3
    @mock_dynamodb
    def setUp(self):
        """ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        # S3ãƒã‚±ãƒƒãƒˆä½œæˆ
        self.s3_client = boto3.client('s3', region_name='us-east-1')
        self.s3_client.create_bucket(Bucket='test-documents-bucket')
        self.s3_client.create_bucket(Bucket='test-temp-processing-bucket')
        
        # DynamoDBãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
        self.dynamodb = boto3.resource('dynamodb', region_name='us-east-1')
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
        self.metadata_table = self.dynamodb.create_table(
            TableName='test-metadata-table',
            KeySchema=[
                {'AttributeName': 'processing_id', 'KeyType': 'HASH'}
            ],
            AttributeDefinitions=[
                {'AttributeName': 'processing_id', 'AttributeType': 'S'}
            ],
            BillingMode='PAY_PER_REQUEST'
        )
        
        # è¿½è·¡ãƒ†ãƒ¼ãƒ–ãƒ«
        self.tracking_table = self.dynamodb.create_table(
            TableName='test-tracking-table',
            KeySchema=[
                {'AttributeName': 'fileHash', 'KeyType': 'HASH'}
            ],
            AttributeDefinitions=[
                {'AttributeName': 'fileHash', 'AttributeType': 'S'}
            ],
            BillingMode='PAY_PER_REQUEST'
        )
    
    @mock_s3
    @mock_dynamodb
    def test_s3_event_processing(self):
        """S3ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†ã®çµ±åˆãƒ†ã‚¹ãƒˆ"""
        # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’S3ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        test_content = b'Test document content for S3 integration testing'
        self.s3_client.put_object(
            Bucket='test-documents-bucket',
            Key='test-documents/integration-test.txt',
            Body=test_content
        )
        
        # S3ã‚¤ãƒ™ãƒ³ãƒˆã‚’æ¨¡æ“¬
        s3_event = {
            'Records': [{
                's3': {
                    'bucket': {'name': 'test-documents-bucket'},
                    'object': {'key': 'test-documents/integration-test.txt'}
                }
            }]
        }
        
        # Lambdaé–¢æ•°å®Ÿè¡Œ
        with patch('document_processor.boto3.client') as mock_boto3:
            mock_s3 = Mock()
            mock_s3.get_object.return_value = {
                'Body': Mock()
            }
            mock_s3.get_object.return_value['Body'].read.return_value = test_content
            mock_boto3.return_value = mock_s3
            
            result = lambda_handler(s3_event, {})
        
        # çµæœæ¤œè¨¼
        self.assertEqual(result['statusCode'], 200)
        body = json.loads(result['body'])
        self.assertTrue(body['success'])
    
    @mock_s3
    @mock_dynamodb
    def test_api_gateway_processing(self):
        """API GatewayçµŒç”±ã®å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        # API Gatewayã‚¤ãƒ™ãƒ³ãƒˆã‚’æ¨¡æ“¬
        api_event = {
            'body': json.dumps({
                'fileName': 'api-test.pdf',
                'fileContent': 'VGVzdCBQREYgY29udGVudA==',  # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
                'processingStrategy': 'both-compare'
            }),
            'requestContext': {
                'authorizer': {
                    'claims': {
                        'sub': 'test-user-id'
                    }
                }
            },
            'queryStringParameters': {
                'projectId': 'test-project'
            }
        }
        
        # Lambdaé–¢æ•°å®Ÿè¡Œ
        result = lambda_handler(api_event, {})
        
        # çµæœæ¤œè¨¼
        self.assertIn('statusCode', result)
        body = json.loads(result['body'])
        self.assertIn('success', body)
    
    @mock_s3
    @mock_dynamodb
    @patch('document_processor.BedrockKBVectorProcessor')
    @patch('document_processor.LangChainIntegration')
    def test_end_to_end_processing(self, mock_langchain, mock_vector):
        """ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        # LangChainã®ãƒ¢ãƒƒã‚¯è¨­å®š
        mock_langchain_instance = Mock()
        mock_langchain_instance.process_markdown_content.return_value = Mock(
            success=True,
            chunks=[
                {'content': 'ãƒãƒ£ãƒ³ã‚¯1', 'metadata': {'chunk_type': 'paragraph'}},
                {'content': 'ãƒãƒ£ãƒ³ã‚¯2', 'metadata': {'chunk_type': 'header'}}
            ],
            embeddings=[[0.1] * 1536, [0.2] * 1536],
            metadata={'chunk_size': 1000, 'total_processing_time': 800}
        )
        mock_langchain.return_value = mock_langchain_instance
        
        # ãƒ™ã‚¯ãƒˆãƒ«å‡¦ç†ã®ãƒ¢ãƒƒã‚¯è¨­å®š
        mock_vector_instance = Mock()
        mock_vector_instance.generate_embeddings.return_value = Mock(
            success=True,
            embeddings=[[0.1] * 1536, [0.2] * 1536],
            metadata={'total_processing_time': 3000, 'batch_size': 2}
        )
        mock_vector_instance.create_bedrock_kb_documents.return_value = [
            Mock(id='doc1', content='ãƒãƒ£ãƒ³ã‚¯1'),
            Mock(id='doc2', content='ãƒãƒ£ãƒ³ã‚¯2')
        ]
        mock_vector_instance.store_embeddings_to_opensearch.return_value = {
            'success': True,
            'stored_count': 2,
            'processing_time': 0.5
        }
        mock_vector.return_value = mock_vector_instance
        
        # å‡¦ç†å®Ÿè¡Œ
        processor = DocumentProcessor()
        result = processor.process_document(
            file_content=b'Test content for end-to-end testing',
            file_name='e2e-test.txt',
            processing_strategy='markitdown-first',
            user_id='test-user',
            project_id='test-project'
        )
        
        # çµæœæ¤œè¨¼
        self.assertIsInstance(result, dict)
        self.assertIn('success', result)


class TestPerformanceAndScaling(unittest.TestCase):
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ"""
    
    def setUp(self):
        """ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        with patch('document_processor.boto3.resource'), \
             patch('document_processor.boto3.client'):
            self.processor = DocumentProcessor()
    
    def test_large_file_processing(self):
        """å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        # å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ï¼ˆ1MBï¼‰
        large_content = b'Large file content for testing. ' * 30000
        
        result = self.processor.process_document(
            file_content=large_content,
            file_name='large-test.txt',
            processing_strategy='markitdown-first'
        )
        
        # å‡¦ç†çµæœã®æ¤œè¨¼
        self.assertIsInstance(result, dict)
        self.assertIn('success', result)
        
        # å‡¦ç†æ™‚é–“ã®ç¢ºèª
        if result['success']:
            processing_time = result['metadata']['totalProcessingTime']
            self.assertGreater(processing_time, 0)
            print(f"å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†æ™‚é–“: {processing_time:.2f}ms")
    
    def test_concurrent_processing_simulation(self):
        """ä¸¦è¡Œå‡¦ç†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ"""
        import threading
        import time
        
        results = []
        
        def process_file(file_index):
            """ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†é–¢æ•°"""
            content = f'Concurrent test file {file_index} content'.encode()
            result = self.processor.process_document(
                file_content=content,
                file_name=f'concurrent-test-{file_index}.txt',
                processing_strategy='markitdown-first'
            )
            results.append(result)
        
        # 5ã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸¦è¡Œå‡¦ç†
        threads = []
        for i in range(5):
            thread = threading.Thread(target=process_file, args=(i,))
            threads.append(thread)
            thread.start()
        
        # å…¨ã‚¹ãƒ¬ãƒƒãƒ‰ã®å®Œäº†ã‚’å¾…æ©Ÿ
        for thread in threads:
            thread.join()
        
        # çµæœæ¤œè¨¼
        self.assertEqual(len(results), 5)
        for result in results:
            self.assertIsInstance(result, dict)
            self.assertIn('success', result)


class TestSecurityAndValidation(unittest.TestCase):
    """ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¨æ¤œè¨¼ã®ãƒ†ã‚¹ãƒˆ"""
    
    def setUp(self):
        """ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        with patch('document_processor.boto3.resource'), \
             patch('document_processor.boto3.client'):
            self.processor = DocumentProcessor()
    
    def test_file_size_validation(self):
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºæ¤œè¨¼ãƒ†ã‚¹ãƒˆ"""
        # åˆ¶é™ã‚’è¶…ãˆã‚‹å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ100MBï¼‰
        oversized_content = b'X' * (100 * 1024 * 1024)
        
        result = self.processor.process_document(
            file_content=oversized_content,
            file_name='oversized.txt'
        )
        
        # ã‚µã‚¤ã‚ºåˆ¶é™ã‚¨ãƒ©ãƒ¼ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        if not result['success']:
            self.assertIn('error', result)
            print(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºåˆ¶é™ã‚¨ãƒ©ãƒ¼: {result['error']['message']}")
    
    def test_malicious_content_handling(self):
        """æ‚ªæ„ã®ã‚ã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        # æ‚ªæ„ã®ã‚ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å«ã‚€HTML
        malicious_html = b'''
        <html>
        <script>alert('XSS');</script>
        <body>Test content</body>
        </html>
        '''
        
        result = self.processor.process_document(
            file_content=malicious_html,
            file_name='malicious.html'
        )
        
        # å‡¦ç†çµæœã®æ¤œè¨¼ï¼ˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å‡¦ç†ãŒé©åˆ‡ã«è¡Œã‚ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèªï¼‰
        self.assertIsInstance(result, dict)
        if result['success']:
            # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å‡ºåŠ›ã«ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚¿ã‚°ãŒå«ã¾ã‚Œã¦ã„ãªã„ã“ã¨ã‚’ç¢ºèª
            markdown_content = result.get('markdownContent', '')
            self.assertNotIn('<script>', markdown_content)
            self.assertNotIn('alert(', markdown_content)


def run_integration_tests():
    """çµ±åˆãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ"""
    print("ğŸ”— Markitdownçµ±åˆæ©Ÿèƒ½ çµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹")
    print(f"å®Ÿè¡Œæ—¥æ™‚: {datetime.now().isoformat()}")
    print("=" * 80)
    
    # ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆã®ä½œæˆ
    test_suite = unittest.TestSuite()
    
    # çµ±åˆãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹ã‚’è¿½åŠ 
    test_classes = [
        TestS3ToOpenSearchIntegration,
        TestPerformanceAndScaling,
        TestSecurityAndValidation
    ]
    
    for test_class in test_classes:
        tests = unittest.TestLoader().loadTestsFromTestCase(test_class)
        test_suite.addTests(tests)
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(test_suite)
    
    print("=" * 80)
    print(f"ğŸ¯ çµ±åˆãƒ†ã‚¹ãƒˆçµæœ: {result.testsRun}ä»¶å®Ÿè¡Œ")
    print(f"âœ… æˆåŠŸ: {result.testsRun - len(result.failures) - len(result.errors)}ä»¶")
    print(f"âŒ å¤±æ•—: {len(result.failures)}ä»¶")
    print(f"ğŸ’¥ ã‚¨ãƒ©ãƒ¼: {len(result.errors)}ä»¶")
    
    if result.failures:
        print("\nâŒ å¤±æ•—ã—ãŸãƒ†ã‚¹ãƒˆ:")
        for test, traceback in result.failures:
            print(f"  - {test}")
    
    if result.errors:
        print("\nğŸ’¥ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸãƒ†ã‚¹ãƒˆ:")
        for test, traceback in result.errors:
            print(f"  - {test}")
    
    print("\nğŸ‰ çµ±åˆãƒ†ã‚¹ãƒˆå®Œäº†")
    return result.wasSuccessful()


if __name__ == "__main__":
    success = run_integration_tests()
    sys.exit(0 if success else 1)