"""
Amazon Bedrock Knowledge Baseäº’æ›ãƒ™ã‚¯ãƒˆãƒ«åŸ‹ã‚è¾¼ã¿ç”Ÿæˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
Bedrock KBæ¨™æº–ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¯¾å¿œã—ãŸOpenSearch Serverlessçµ±åˆ
"""

import json
import logging
import os
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
import boto3
from botocore.exceptions import ClientError
import hashlib
from datetime import datetime
import time
import sys

# æ§‹é€ åŒ–ãƒ­ã‚°è¨­å®š
class StructuredLogger:
    """æ§‹é€ åŒ–ãƒ­ã‚°å‡ºåŠ›ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, name: str):
        self.logger = logging.getLogger(name)
        self._setup_logger()
    
    def _setup_logger(self):
        """ãƒ­ã‚°è¨­å®šã®åˆæœŸåŒ–"""
        if not self.logger.handlers:
            handler = logging.StreamHandler(sys.stdout)
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)
            self.logger.setLevel(logging.INFO)
    
    def info(self, message: str, **kwargs):
        """æƒ…å ±ãƒ­ã‚°"""
        if kwargs:
            self.logger.info(f"{message} | {json.dumps(kwargs, ensure_ascii=False)}")
        else:
            self.logger.info(message)
    
    def warning(self, message: str, **kwargs):
        """è­¦å‘Šãƒ­ã‚°"""
        if kwargs:
            self.logger.warning(f"{message} | {json.dumps(kwargs, ensure_ascii=False)}")
        else:
            self.logger.warning(message)
    
    def error(self, message: str, **kwargs):
        """ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°"""
        if kwargs:
            self.logger.error(f"{message} | {json.dumps(kwargs, ensure_ascii=False)}")
        else:
            self.logger.error(message)

logger = StructuredLogger(__name__)

@dataclass
class EmbeddingResult:
    """åŸ‹ã‚è¾¼ã¿çµæœ"""
    success: bool
    embeddings: List[List[float]]
    metadata: Dict[str, Any]
    error: Optional[str] = None

@dataclass
class BedrockKBDocument:
    """Bedrock Knowledge Baseäº’æ›OpenSearchãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ"""
    id: str
    content: str
    embedding: List[float]
    metadata: Dict[str, Any]
    timestamp: str

class BedrockKBVectorProcessor:
    """Bedrock Knowledge Baseäº’æ›ãƒ™ã‚¯ãƒˆãƒ«åŸ‹ã‚è¾¼ã¿å‡¦ç†ã‚¯ãƒ©ã‚¹"""
    
    # ã‚¯ãƒ©ã‚¹å®šæ•°
    DEFAULT_EMBEDDING_MODEL = 'amazon.titan-embed-text-v1'
    DEFAULT_REGION = 'us-east-1'
    DEFAULT_INDEX = 'bedrock-knowledge-base-default-index'
    MAX_TEXT_LENGTH = 8000
    EMBEDDING_DIMENSION = 1536
    
    def __init__(self, 
                 region: str = None,
                 embedding_model: str = None,
                 opensearch_endpoint: Optional[str] = None,
                 opensearch_index: str = None,
                 config: Optional[Dict[str, Any]] = None):
        """
        åˆæœŸåŒ–ï¼ˆè¨­å®šç®¡ç†å¼·åŒ–ç‰ˆï¼‰
        
        Args:
            region: AWSãƒªãƒ¼ã‚¸ãƒ§ãƒ³
            embedding_model: åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«å
            opensearch_endpoint: OpenSearchã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
            opensearch_index: OpenSearchã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å
            config: è¨­å®šè¾æ›¸ï¼ˆå„ªå…ˆåº¦æœ€é«˜ï¼‰
        """
        # è¨­å®šã®å„ªå…ˆé †ä½: config > å¼•æ•° > ç’°å¢ƒå¤‰æ•° > ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        if config:
            self.region = config.get('region') or region or os.environ.get('AWS_REGION') or self.DEFAULT_REGION
            self.embedding_model = config.get('embedding_model') or embedding_model or os.environ.get('EMBEDDING_MODEL') or self.DEFAULT_EMBEDDING_MODEL
            self.opensearch_endpoint = config.get('opensearch_endpoint') or opensearch_endpoint or os.environ.get('OPENSEARCH_ENDPOINT')
            self.opensearch_index = config.get('opensearch_index') or opensearch_index or os.environ.get('OPENSEARCH_INDEX') or self.DEFAULT_INDEX
        else:
            self.region = region or os.environ.get('AWS_REGION') or self.DEFAULT_REGION
            self.embedding_model = embedding_model or os.environ.get('EMBEDDING_MODEL') or self.DEFAULT_EMBEDDING_MODEL
            self.opensearch_endpoint = opensearch_endpoint or os.environ.get('OPENSEARCH_ENDPOINT')
            self.opensearch_index = opensearch_index or os.environ.get('OPENSEARCH_INDEX') or self.DEFAULT_INDEX
        
        # è¨­å®šæ¤œè¨¼
        self._validate_configuration()
        
        # AWS ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
        try:
            self.bedrock_client = boto3.client('bedrock-runtime', region_name=self.region)
        except Exception as e:
            logger.error(f"Bedrockã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            raise ValueError(f"Bedrockã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        
        self.opensearch_client = None  # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ opensearch-py ã‚’ä½¿ç”¨
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨­å®š
        self.max_retries = int(os.environ.get('BEDROCK_MAX_RETRIES', '3'))
        self.request_timeout = int(os.environ.get('BEDROCK_TIMEOUT', '30'))
        
        logger.info(f"Bedrock KBäº’æ›ãƒ™ã‚¯ãƒˆãƒ«å‡¦ç†ã‚’åˆæœŸåŒ–: model={self.embedding_model}, region={self.region}, endpoint={self.opensearch_endpoint}")
    
    def _validate_configuration(self) -> None:
        """è¨­å®šå€¤ã®æ¤œè¨¼"""
        # ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã®æ¤œè¨¼
        valid_regions = [
            'us-east-1', 'us-west-2', 'eu-west-1', 'eu-central-1', 
            'ap-northeast-1', 'ap-southeast-1', 'ap-southeast-2'
        ]
        if self.region not in valid_regions:
            logger.warning(f"æœªæ¤œè¨¼ã®ãƒªãƒ¼ã‚¸ãƒ§ãƒ³: {self.region}")
        
        # åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®æ¤œè¨¼
        valid_models = [
            'amazon.titan-embed-text-v1',
            'amazon.titan-embed-text-v2:0',
            'cohere.embed-english-v3',
            'cohere.embed-multilingual-v3'
        ]
        if self.embedding_model not in valid_models:
            logger.warning(f"æœªæ¤œè¨¼ã®åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«: {self.embedding_model}")
        
        # OpenSearchã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®æ¤œè¨¼
        if self.opensearch_endpoint:
            if not self.opensearch_endpoint.startswith('https://'):
                raise ValueError("OpenSearchã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¯HTTPS URLã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åã®æ¤œè¨¼
        if not self.opensearch_index or len(self.opensearch_index) < 1:
            raise ValueError("OpenSearchã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åãŒç„¡åŠ¹ã§ã™")
    
    def generate_embeddings(self, texts: List[str], batch_size: int = 25, enable_cache: bool = True) -> EmbeddingResult:
        """
        ãƒ†ã‚­ã‚¹ãƒˆãƒªã‚¹ãƒˆã®åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆï¼ˆæœ€é©åŒ–ç‰ˆï¼‰
        
        Args:
            texts: ãƒ†ã‚­ã‚¹ãƒˆãƒªã‚¹ãƒˆ
            batch_size: ãƒãƒƒãƒã‚µã‚¤ã‚º
            enable_cache: ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ã®æœ‰åŠ¹åŒ–
            
        Returns:
            EmbeddingResult: åŸ‹ã‚è¾¼ã¿çµæœ
        """
        # å…¥åŠ›æ¤œè¨¼
        if not texts:
            return EmbeddingResult(
                success=False,
                embeddings=[],
                metadata={},
                error="ãƒ†ã‚­ã‚¹ãƒˆãƒªã‚¹ãƒˆãŒç©ºã§ã™"
            )
        
        if not isinstance(texts, list):
            return EmbeddingResult(
                success=False,
                embeddings=[],
                metadata={},
                error="ãƒ†ã‚­ã‚¹ãƒˆã¯ãƒªã‚¹ãƒˆå½¢å¼ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
            )
        
        # ãƒãƒƒãƒã‚µã‚¤ã‚ºã®æœ€é©åŒ–
        optimal_batch_size = min(batch_size, 50)  # APIåˆ¶é™ã‚’è€ƒæ…®
        if batch_size != optimal_batch_size:
            logger.info(f"ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’æœ€é©åŒ–: {batch_size} -> {optimal_batch_size}")
            batch_size = optimal_batch_size
        
        try:
            logger.info(f"ğŸ”¢ åŸ‹ã‚è¾¼ã¿ç”Ÿæˆé–‹å§‹: {len(texts)}ãƒ†ã‚­ã‚¹ãƒˆ (ãƒãƒƒãƒã‚µã‚¤ã‚º: {batch_size})")
            
            all_embeddings = []
            processing_times = []
            cache_hits = 0
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®åˆæœŸåŒ–ï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
            embedding_cache = {} if enable_cache else None
            
            # ãƒãƒƒãƒå‡¦ç†
            for i in range(0, len(texts), batch_size):
                batch_texts = texts[i:i + batch_size]
                batch_start_time = time.time()
                
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
                if embedding_cache is not None:
                    cached_embeddings = []
                    uncached_texts = []
                    uncached_indices = []
                    
                    for j, text in enumerate(batch_texts):
                        text_hash = hashlib.md5(text.encode()).hexdigest()
                        if text_hash in embedding_cache:
                            cached_embeddings.append((j, embedding_cache[text_hash]))
                            cache_hits += 1
                        else:
                            uncached_texts.append(text)
                            uncached_indices.append(j)
                    
                    # æœªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ãƒ†ã‚­ã‚¹ãƒˆã®ã¿å‡¦ç†
                    if uncached_texts:
                        new_embeddings = self._generate_batch_embeddings(uncached_texts)
                        
                        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
                        for text, embedding in zip(uncached_texts, new_embeddings):
                            text_hash = hashlib.md5(text.encode()).hexdigest()
                            embedding_cache[text_hash] = embedding
                    else:
                        new_embeddings = []
                    
                    # çµæœã‚’ãƒãƒ¼ã‚¸
                    batch_embeddings = [None] * len(batch_texts)
                    
                    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸåŸ‹ã‚è¾¼ã¿ã‚’é…ç½®
                    for j, embedding in cached_embeddings:
                        batch_embeddings[j] = embedding
                    
                    # æ–°ã—ã„åŸ‹ã‚è¾¼ã¿ã‚’é…ç½®
                    new_idx = 0
                    for j in uncached_indices:
                        if new_idx < len(new_embeddings):
                            batch_embeddings[j] = new_embeddings[new_idx]
                            new_idx += 1
                else:
                    batch_embeddings = self._generate_batch_embeddings(batch_texts)
                
                all_embeddings.extend(batch_embeddings)
                
                batch_time = time.time() - batch_start_time
                processing_times.append(batch_time)
                
                logger.info(f"ãƒãƒƒãƒ {i//batch_size + 1}/{(len(texts) + batch_size - 1)//batch_size} å®Œäº†: {len(batch_texts)}ãƒ†ã‚­ã‚¹ãƒˆ, {batch_time:.2f}ç§’")
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æ‹¡å¼µ
            metadata = {
                'total_texts': len(texts),
                'total_embeddings': len(all_embeddings),
                'batch_size': batch_size,
                'embedding_model': self.embedding_model,
                'total_processing_time': sum(processing_times),
                'average_batch_time': sum(processing_times) / len(processing_times) if processing_times else 0,
                'embedding_dimension': len(all_embeddings[0]) if all_embeddings else 0,
                'processed_at': datetime.utcnow().isoformat(),
                'cache_enabled': enable_cache,
                'cache_hits': cache_hits,
                'cache_hit_rate': cache_hits / len(texts) if texts else 0,
                'throughput_texts_per_second': len(texts) / sum(processing_times) if processing_times else 0
            }
            
            logger.info(f"âœ… åŸ‹ã‚è¾¼ã¿ç”Ÿæˆå®Œäº†: {len(all_embeddings)}åŸ‹ã‚è¾¼ã¿, {sum(processing_times):.2f}ç§’")
            if enable_cache:
                logger.info(f"ğŸ“Š ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆ: ãƒ’ãƒƒãƒˆç‡ {metadata['cache_hit_rate']:.1%} ({cache_hits}/{len(texts)})")
            
            return EmbeddingResult(
                success=True,
                embeddings=all_embeddings,
                metadata=metadata
            )
            
        except Exception as e:
            logger.error(f"âŒ åŸ‹ã‚è¾¼ã¿ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return EmbeddingResult(
                success=False,
                embeddings=[],
                metadata={
                    'total_texts': len(texts),
                    'error_occurred_at': datetime.utcnow().isoformat()
                },
                error=str(e)
            )
    
    def _generate_batch_embeddings(self, texts: List[str]) -> List[List[float]]:
        """
        ãƒãƒƒãƒã§ã®åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
        
        Args:
            texts: ãƒ†ã‚­ã‚¹ãƒˆãƒªã‚¹ãƒˆ
            
        Returns:
            List[List[float]]: åŸ‹ã‚è¾¼ã¿ãƒªã‚¹ãƒˆ
        """
        embeddings = []
        
        for text in texts:
            try:
                # Bedrock Titan Embeddings ã‚’ä½¿ç”¨
                embedding = self._invoke_bedrock_embedding(text)
                embeddings.append(embedding)
                
            except Exception as e:
                logger.warning(f"å€‹åˆ¥ãƒ†ã‚­ã‚¹ãƒˆã®åŸ‹ã‚è¾¼ã¿ç”Ÿæˆã«å¤±æ•—: {e}")
                # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ã‚¼ãƒ­ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä½¿ç”¨
                embeddings.append([0.0] * 1536)  # Titan Embeddings ã®æ¬¡å…ƒæ•°
        
        return embeddings
    
    def _invoke_bedrock_embedding(self, text: str, retry_count: int = 0) -> List[float]:
        """
        BedrockåŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’å‘¼ã³å‡ºã—ï¼ˆæ”¹å–„ç‰ˆï¼‰
        
        Args:
            text: å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
            retry_count: ãƒªãƒˆãƒ©ã‚¤å›æ•°
            
        Returns:
            List[float]: åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«
        """
        max_retries = 3
        base_delay = 1.0
        
        try:
            # ãƒ†ã‚­ã‚¹ãƒˆã®å‰å‡¦ç†
            processed_text = self._preprocess_text(text)
            
            # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã®æ¤œè¨¼
            request_body = {
                "inputText": processed_text
            }
            
            # JSON ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã®æ¤œè¨¼
            try:
                json_body = json.dumps(request_body, ensure_ascii=False)
            except (TypeError, ValueError) as e:
                raise ValueError(f"ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã®JSONå¤‰æ›ã«å¤±æ•—: {e}")
            
            # Bedrock APIå‘¼ã³å‡ºã—
            response = self.bedrock_client.invoke_model(
                modelId=self.embedding_model,
                body=json_body,
                contentType='application/json',
                accept='application/json'
            )
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®æ¤œè¨¼
            if not response or 'body' not in response:
                raise ValueError("Bedrockã‹ã‚‰ã®ç„¡åŠ¹ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹")
            
            try:
                response_body = json.loads(response['body'].read())
            except json.JSONDecodeError as e:
                raise ValueError(f"Bedrockãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®JSONè§£æã«å¤±æ•—: {e}")
            
            embedding = response_body.get('embedding', [])
            
            # åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã®æ¤œè¨¼
            if not embedding:
                raise ValueError("åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ãŒç©ºã§ã™")
            
            if not isinstance(embedding, list) or not all(isinstance(x, (int, float)) for x in embedding):
                raise ValueError("åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã®å½¢å¼ãŒç„¡åŠ¹ã§ã™")
            
            # æ¬¡å…ƒæ•°ã®æ¤œè¨¼
            expected_dim = 1536  # Titan Embeddings
            if len(embedding) != expected_dim:
                logger.warning(f"äºˆæœŸã—ãªã„åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒæ•°: {len(embedding)} (æœŸå¾…å€¤: {expected_dim})")
            
            return embedding
            
        except ClientError as e:
            error_code = e.response['Error']['Code']
            
            if error_code == 'ThrottlingException' and retry_count < max_retries:
                # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ã§ãƒªãƒˆãƒ©ã‚¤
                delay = base_delay * (2 ** retry_count)
                logger.warning(f"Bedrockã‚¹ãƒ­ãƒƒãƒˆãƒªãƒ³ã‚°ç™ºç”Ÿã€{delay}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™ (è©¦è¡Œ {retry_count + 1}/{max_retries})")
                time.sleep(delay)
                return self._invoke_bedrock_embedding(text, retry_count + 1)
            
            elif error_code == 'ValidationException':
                logger.error(f"Bedrockå…¥åŠ›æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
                raise ValueError(f"å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ãŒç„¡åŠ¹ã§ã™: {e}")
            
            elif error_code == 'AccessDeniedException':
                logger.error(f"Bedrockã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ã‚¨ãƒ©ãƒ¼: {e}")
                raise PermissionError(f"Bedrockã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸ: {e}")
            
            else:
                logger.error(f"Bedrock APIã‚¨ãƒ©ãƒ¼ [{error_code}]: {e}")
                raise
                
        except Exception as e:
            logger.error(f"BedrockåŸ‹ã‚è¾¼ã¿å‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}")
            
            # æœ¬ç•ªç’°å¢ƒã§ã¯ãƒ¢ãƒƒã‚¯åŸ‹ã‚è¾¼ã¿ã‚’ä½¿ç”¨ã—ãªã„
            if os.environ.get('ENVIRONMENT', 'prod') == 'prod':
                raise
            else:
                logger.warning("é–‹ç™ºç’°å¢ƒã®ãŸã‚ãƒ¢ãƒƒã‚¯åŸ‹ã‚è¾¼ã¿ã‚’ä½¿ç”¨ã—ã¾ã™")
                return self._generate_mock_embedding(text)
    
    def _preprocess_text(self, text: str) -> str:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã®å‰å‡¦ç†ï¼ˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–ç‰ˆï¼‰
        
        Args:
            text: å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            str: å‰å‡¦ç†æ¸ˆã¿ãƒ†ã‚­ã‚¹ãƒˆ
        """
        # å…¥åŠ›æ¤œè¨¼
        if not isinstance(text, str):
            raise ValueError(f"ãƒ†ã‚­ã‚¹ãƒˆã¯æ–‡å­—åˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™: {type(text)}")
        
        # åŸºæœ¬çš„ãªã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
        processed = text.strip()
        
        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: æ‚ªæ„ã®ã‚ã‚‹æ–‡å­—åˆ—ã®é™¤å»
        import re
        # åˆ¶å¾¡æ–‡å­—ã®é™¤å»ï¼ˆæ”¹è¡Œãƒ»ã‚¿ãƒ–ã¯ä¿æŒï¼‰
        processed = re.sub(r'[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]', '', processed)
        
        # SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³å¯¾ç­–ï¼ˆåŸºæœ¬çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
        suspicious_patterns = [
            r'(?i)(union\s+select|drop\s+table|delete\s+from|insert\s+into)',
            r'(?i)(script\s*>|javascript:|vbscript:)',
            r'[\x00-\x08\x0B\x0C\x0E-\x1F\x7F-\x9F]'  # åˆ¶å¾¡æ–‡å­—
        ]
        
        for pattern in suspicious_patterns:
            if re.search(pattern, processed):
                logger.warning(f"ç–‘ã‚ã—ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡ºã€ã‚µãƒ‹ã‚¿ã‚¤ã‚ºã—ã¾ã™: {pattern}")
                processed = re.sub(pattern, '[SANITIZED]', processed)
        
        # é•·ã™ãã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒˆãƒ©ãƒ³ã‚±ãƒ¼ãƒˆï¼ˆTitan Embeddings ã®åˆ¶é™ï¼‰
        max_length = 8000  # æ–‡å­—æ•°åˆ¶é™
        if len(processed) > max_length:
            processed = processed[:max_length]
            logger.warning(f"ãƒ†ã‚­ã‚¹ãƒˆãŒé•·ã™ãã‚‹ãŸã‚åˆ‡ã‚Šè©°ã‚ã¾ã—ãŸ: {len(text)} -> {len(processed)}æ–‡å­—")
        
        # ç©ºã®ãƒ†ã‚­ã‚¹ãƒˆã®å‡¦ç†
        if not processed:
            processed = "[ç©ºã®ãƒ†ã‚­ã‚¹ãƒˆ]"
        
        return processed
    
    def _generate_mock_embedding(self, text: str) -> List[float]:
        """
        ãƒ¢ãƒƒã‚¯åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰
        
        Args:
            text: å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            List[float]: ãƒ¢ãƒƒã‚¯åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«
        """
        # ãƒ†ã‚­ã‚¹ãƒˆã®ãƒãƒƒã‚·ãƒ¥ã«åŸºã¥ã„ã¦ãƒ€ãƒŸãƒ¼åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆ
        text_hash = hashlib.md5(text.encode()).hexdigest()
        
        embedding = []
        for i in range(1536):  # Titan Embeddings ã®æ¬¡å…ƒæ•°
            # ãƒãƒƒã‚·ãƒ¥å€¤ã‚’ä½¿ã£ã¦ç–‘ä¼¼ãƒ©ãƒ³ãƒ€ãƒ ãªå€¤ã‚’ç”Ÿæˆ
            hash_int = int(text_hash[i % len(text_hash)], 16)
            value = (hash_int + i) / 1000.0 - 0.5  # -0.5 ã‹ã‚‰ 0.5 ã®ç¯„å›²
            embedding.append(value)
        
        return embedding
    
    def create_bedrock_kb_documents(self, 
                                   chunks: List[Dict[str, Any]], 
                                   embeddings: List[List[float]],
                                   source_file: str,
                                   source_uri: Optional[str] = None,
                                   author: Optional[str] = None,
                                   file_size: Optional[int] = None,
                                   parent_chunks: Optional[List[str]] = None) -> List[BedrockKBDocument]:
        """
        Amazon Bedrock Knowledge Baseäº’æ›ã®OpenSearchãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä½œæˆ
        
        Args:
            chunks: ãƒãƒ£ãƒ³ã‚¯ãƒªã‚¹ãƒˆ
            embeddings: åŸ‹ã‚è¾¼ã¿ãƒªã‚¹ãƒˆ
            source_file: ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«å
            source_uri: ã‚½ãƒ¼ã‚¹URIï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼‰
            author: ä½œæˆè€…
            file_size: ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º
            parent_chunks: è¦ªãƒãƒ£ãƒ³ã‚¯ãƒ†ã‚­ã‚¹ãƒˆãƒªã‚¹ãƒˆ
            
        Returns:
            List[BedrockKBDocument]: Bedrock KBäº’æ›OpenSearchãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒªã‚¹ãƒˆ
        """
        documents = []
        timestamp = datetime.utcnow().isoformat()
        
        for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):
            doc_id = self._generate_document_id(source_file, i, chunk['content'])
            
            # è¦ªãƒãƒ£ãƒ³ã‚¯ãƒ†ã‚­ã‚¹ãƒˆã®å–å¾—
            parent_text = parent_chunks[i] if parent_chunks and i < len(parent_chunks) else ""
            
            # ãƒšãƒ¼ã‚¸ç•ªå·ã®æ¨å®šï¼ˆãƒãƒ£ãƒ³ã‚¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‹ã‚‰ï¼‰
            estimated_page = max(1, (i // 3) + 1)  # 3ãƒãƒ£ãƒ³ã‚¯ã”ã¨ã«1ãƒšãƒ¼ã‚¸ã¨ä»®å®š
            
            # Amazon Bedrock Knowledge Baseäº’æ›ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            bedrock_metadata = {
                "source": source_uri or source_file,
                "parentText": parent_text
            }
            
            # Bedrock KBæ¨™æº–ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’å«ã‚€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            enhanced_metadata = {
                # Bedrock Knowledge Baseæ¨™æº–ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
                "x-amz-bedrock-kb-category": "File",
                "AMAZON_BEDROCK_METADATA": json.dumps(bedrock_metadata),
                "x-amz-bedrock-kb-lastModifiedDateTime": timestamp,
                "x-amz-bedrock-kb-createdDate": timestamp,
                "x-amz-bedrock-kb-source-uri": source_uri or source_file,
                "x-amz-bedrock-kb-document-page-number": estimated_page,
                "x-amz-bedrock-kb-size": str(file_size) if file_size else str(len(chunk['content'])),
                "x-amz-bedrock-kb-title": source_file,
                "AMAZON_BEDROCK_TEXT_CHUNK": chunk['content'],
                "x-amz-bedrock-kb-author": author or "system",
                
                # è¿½åŠ ã®ã‚«ã‚¹ã‚¿ãƒ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
                **chunk['metadata'],
                'document_id': doc_id,
                'embedding_model': self.embedding_model,
                'embedding_dimension': len(embedding),
                'indexed_at': timestamp,
                'chunk_index': i,
                'chunk_type': chunk['metadata'].get('chunk_type', 'paragraph')
            }
            
            # OpenSearchãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæˆï¼ˆBedrock KBäº’æ›ï¼‰
            doc = BedrockKBDocument(
                id=doc_id,
                content=chunk['content'],
                embedding=embedding,
                metadata=enhanced_metadata,
                timestamp=timestamp
            )
            
            documents.append(doc)
        
        return documents
    
    def store_embeddings_to_opensearch(self, 
                                     documents: List[BedrockKBDocument],
                                     index_name: Optional[str] = None) -> Dict[str, Any]:
        """
        Bedrock KBäº’æ›åŸ‹ã‚è¾¼ã¿ã‚’OpenSearch Serverlessã«æ ¼ç´
        
        Args:
            documents: BedrockKBãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒªã‚¹ãƒˆ
            index_name: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            
        Returns:
            Dict: æ ¼ç´çµæœ
        """
        try:
            index = index_name or self.opensearch_index
            logger.info(f"ğŸ“Š Bedrock KBäº’æ›OpenSearchæ ¼ç´é–‹å§‹: {len(documents)}ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ -> {index}")
            
            if not self.opensearch_client:
                logger.warning("OpenSearchã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
                return self._mock_opensearch_storage(documents, index)
            
            # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ä»¥ä¸‹ã‚’ä½¿ç”¨
            # success_count = 0
            # error_count = 0
            # 
            # for doc in documents:
            #     try:
            #         # Bedrock KBäº’æ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ ¼ç´
            #         opensearch_doc = {
            #             "_source": {
            #                 **doc.metadata,
            #                 "bedrock-knowledge-base-default-vector": doc.embedding
            #             }
            #         }
            #         
            #         response = self.opensearch_client.index(
            #             index=index,
            #             id=doc.id,
            #             body=opensearch_doc
            #         )
            #         success_count += 1
            #     except Exception as e:
            #         logger.error(f"ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ ¼ç´ã‚¨ãƒ©ãƒ¼ {doc.id}: {e}")
            #         error_count += 1
            
            # ãƒ¢ãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Ÿè£…
            return self._mock_opensearch_storage(documents, index)
            
        except Exception as e:
            logger.error(f"âŒ Bedrock KBäº’æ›OpenSearchæ ¼ç´ã‚¨ãƒ©ãƒ¼: {e}")
            return {
                'success': False,
                'error': str(e),
                'stored_count': 0,
                'failed_count': len(documents)
            }
    
    def _mock_opensearch_storage(self, documents: List[BedrockKBDocument], index: str) -> Dict[str, Any]:
        """
        Bedrock KBäº’æ›OpenSearchæ ¼ç´ã®ãƒ¢ãƒƒã‚¯å®Ÿè£…
        
        Args:
            documents: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒªã‚¹ãƒˆ
            index: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å
            
        Returns:
            Dict: ãƒ¢ãƒƒã‚¯æ ¼ç´çµæœ
        """
        logger.info(f"ğŸ“Š ãƒ¢ãƒƒã‚¯Bedrock KBäº’æ›OpenSearchæ ¼ç´: {len(documents)}ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ")
        
        # æ ¼ç´ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        time.sleep(0.1 * len(documents))  # æ ¼ç´æ™‚é–“ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        
        # Bedrock KBäº’æ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ã‚µãƒ³ãƒ—ãƒ«å‡ºåŠ›
        sample_doc = documents[0] if documents else None
        if sample_doc:
            logger.info(f"ğŸ“‹ Bedrock KBäº’æ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚µãƒ³ãƒ—ãƒ«:")
            logger.info(f"  - x-amz-bedrock-kb-category: {sample_doc.metadata.get('x-amz-bedrock-kb-category')}")
            logger.info(f"  - x-amz-bedrock-kb-source-uri: {sample_doc.metadata.get('x-amz-bedrock-kb-source-uri')}")
            logger.info(f"  - AMAZON_BEDROCK_TEXT_CHUNK: {sample_doc.metadata.get('AMAZON_BEDROCK_TEXT_CHUNK', '')[:50]}...")
            logger.info(f"  - bedrock-knowledge-base-default-vector: [{len(sample_doc.embedding)}æ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«]")
        
        return {
            'success': True,
            'index': index,
            'stored_count': len(documents),
            'failed_count': 0,
            'processing_time': 0.1 * len(documents),
            'format': 'bedrock-knowledge-base-compatible',
            'mock': True
        }
    
    def _generate_document_id(self, source_file: str, chunk_index: int, content: str) -> str:
        """
        ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆIDã‚’ç”Ÿæˆ
        
        Args:
            source_file: ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«å
            chunk_index: ãƒãƒ£ãƒ³ã‚¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            content: ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
            
        Returns:
            str: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆID
        """
        # ãƒ•ã‚¡ã‚¤ãƒ«åã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã€ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒãƒƒã‚·ãƒ¥ã‚’çµ„ã¿åˆã‚ã›
        content_hash = hashlib.md5(content.encode()).hexdigest()[:8]
        return f"{source_file}_{chunk_index}_{content_hash}"
    
    def search_similar_documents(self, 
                               query_embedding: List[float], 
                               k: int = 10,
                               filter_conditions: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        Bedrock KBäº’æ›é¡ä¼¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ¤œç´¢
        
        Args:
            query_embedding: ã‚¯ã‚¨ãƒªåŸ‹ã‚è¾¼ã¿
            k: å–å¾—ã™ã‚‹æ–‡æ›¸æ•°
            filter_conditions: ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶
            
        Returns:
            Dict: æ¤œç´¢çµæœ
        """
        try:
            logger.info(f"ğŸ” Bedrock KBäº’æ›é¡ä¼¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢: k={k}")
            
            if not self.opensearch_client:
                logger.warning("OpenSearchã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
                return self._mock_similarity_search(query_embedding, k, filter_conditions)
            
            # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ä»¥ä¸‹ã‚’ä½¿ç”¨ï¼ˆBedrock KBäº’æ›ï¼‰
            # search_body = {
            #     "size": k,
            #     "query": {
            #         "script_score": {
            #             "query": {"match_all": {}},
            #             "script": {
            #                 "source": "cosineSimilarity(params.query_vector, 'bedrock-knowledge-base-default-vector') + 1.0",
            #                 "params": {"query_vector": query_embedding}
            #             }
            #         }
            #     },
            #     "_source": {
            #         "includes": [
            #             "x-amz-bedrock-kb-source-uri",
            #             "AMAZON_BEDROCK_TEXT_CHUNK",
            #             "x-amz-bedrock-kb-document-page-number",
            #             "x-amz-bedrock-kb-author",
            #             "AMAZON_BEDROCK_METADATA"
            #         ]
            #     }
            # }
            # 
            # if filter_conditions:
            #     search_body["query"]["script_score"]["query"] = {
            #         "bool": {
            #             "must": [{"match_all": {}}],
            #             "filter": [filter_conditions]
            #         }
            #     }
            # 
            # response = self.opensearch_client.search(
            #     index=self.opensearch_index,
            #     body=search_body
            # )
            
            # ãƒ¢ãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Ÿè£…
            return self._mock_similarity_search(query_embedding, k, filter_conditions)
            
        except Exception as e:
            logger.error(f"âŒ Bedrock KBäº’æ›é¡ä¼¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return {
                'success': False,
                'error': str(e),
                'documents': []
            }
    
    def _mock_similarity_search(self, 
                              query_embedding: List[float], 
                              k: int,
                              filter_conditions: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Bedrock KBäº’æ›é¡ä¼¼æ¤œç´¢ã®ãƒ¢ãƒƒã‚¯å®Ÿè£…
        
        Args:
            query_embedding: ã‚¯ã‚¨ãƒªåŸ‹ã‚è¾¼ã¿
            k: å–å¾—ã™ã‚‹æ–‡æ›¸æ•°
            filter_conditions: ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶
            
        Returns:
            Dict: ãƒ¢ãƒƒã‚¯æ¤œç´¢çµæœ
        """
        logger.info(f"ğŸ” ãƒ¢ãƒƒã‚¯Bedrock KBäº’æ›é¡ä¼¼æ¤œç´¢: k={k}")
        
        # Bedrock KBäº’æ›ãƒ€ãƒŸãƒ¼æ¤œç´¢çµæœã‚’ç”Ÿæˆ
        mock_documents = []
        for i in range(min(k, 5)):  # æœ€å¤§5ä»¶ã®ãƒ€ãƒŸãƒ¼çµæœ
            mock_documents.append({
                '_source': {
                    'x-amz-bedrock-kb-category': 'File',
                    'AMAZON_BEDROCK_METADATA': json.dumps({
                        'source': f'\\\\file\\ishida\\éƒ¨ç½²\\directory\\mock_document_{i}.pdf',
                        'parentText': f'ã“ã‚Œã¯è¦ªãƒãƒ£ãƒ³ã‚¯{i+1}ã®ãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚'
                    }),
                    'x-amz-bedrock-kb-lastModifiedDateTime': datetime.utcnow().isoformat(),
                    'x-amz-bedrock-kb-createdDate': datetime.utcnow().isoformat(),
                    'x-amz-bedrock-kb-source-uri': f'\\\\file\\ishida\\éƒ¨ç½²\\directory\\mock_document_{i}.pdf',
                    'x-amz-bedrock-kb-document-page-number': i + 1,
                    'x-amz-bedrock-kb-size': '1495625',
                    'x-amz-bedrock-kb-title': f'mock_document_{i}.pdf',
                    'AMAZON_BEDROCK_TEXT_CHUNK': f'ã“ã‚Œã¯ãƒ¢ãƒƒã‚¯æ¤œç´¢çµæœ {i+1} ã§ã™ã€‚å®Ÿéš›ã®å®Ÿè£…ã§ã¯é¡ä¼¼åº¦ã®é«˜ã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒè¿”ã•ã‚Œã¾ã™ã€‚',
                    'x-amz-bedrock-kb-author': 'user@example.com',
                    'bedrock-knowledge-base-default-vector': query_embedding[:256] if len(query_embedding) >= 256 else query_embedding  # 256æ¬¡å…ƒã«èª¿æ•´
                },
                '_score': 0.9 - (i * 0.1)  # ã‚¹ã‚³ã‚¢ã‚’é™é †ã§è¨­å®š
            })\n        \n        return {\n            'success': True,\n            'documents': mock_documents,\n            'total_hits': len(mock_documents),\n            'max_score': mock_documents[0]['_score'] if mock_documents else 0,\n            'format': 'bedrock-knowledge-base-compatible',\n            'mock': True\n        }\n    \n    def get_embedding_stats(self) -> Dict[str, Any]:\n        \"\"\"\n        Bedrock KBäº’æ›åŸ‹ã‚è¾¼ã¿å‡¦ç†çµ±è¨ˆã‚’å–å¾—\n        \n        Returns:\n            Dict: çµ±è¨ˆæƒ…å ±\n        \"\"\"\n        return {\n            'embedding_model': self.embedding_model,\n            'region': self.region,\n            'opensearch_endpoint': self.opensearch_endpoint,\n            'opensearch_index': self.opensearch_index,\n            'embedding_dimension': 1536,  # Titan Embeddings\n            'max_text_length': 8000,\n            'format': 'bedrock-knowledge-base-compatible',\n            'supported_operations': ['generate_embeddings', 'store_to_opensearch', 'similarity_search'],\n            'bedrock_kb_fields': [\n                'x-amz-bedrock-kb-category',\n                'AMAZON_BEDROCK_METADATA',\n                'x-amz-bedrock-kb-source-uri',\n                'AMAZON_BEDROCK_TEXT_CHUNK',\n                'bedrock-knowledge-base-default-vector'\n            ]\n        }\n\n\ndef create_bedrock_kb_vector_processor(config: Dict[str, Any]) -> BedrockKBVectorProcessor:\n    \"\"\"\n    Bedrock KBäº’æ›ãƒ™ã‚¯ãƒˆãƒ«åŸ‹ã‚è¾¼ã¿å‡¦ç†ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ\n    \n    Args:\n        config: è¨­å®šè¾æ›¸\n        \n    Returns:\n        BedrockKBVectorProcessor: å‡¦ç†ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹\n    \"\"\"\n    return BedrockKBVectorProcessor(\n        region=config.get('region', 'us-east-1'),\n        embedding_model=config.get('embedding_model', 'amazon.titan-embed-text-v1'),\n        opensearch_endpoint=config.get('opensearch_endpoint'),\n        opensearch_index=config.get('opensearch_index', 'bedrock-knowledge-base-default-index')\n    )\n\n\n# ãƒ†ã‚¹ãƒˆç”¨ã®ã‚µãƒ³ãƒ—ãƒ«é–¢æ•°\ndef test_bedrock_kb_vector_embedding():\n    \"\"\"\n    Bedrock KBäº’æ›ãƒ™ã‚¯ãƒˆãƒ«åŸ‹ã‚è¾¼ã¿å‡¦ç†ã®ãƒ†ã‚¹ãƒˆ\n    \"\"\"\n    # ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆ\n    sample_texts = [\n        \"ã“ã‚Œã¯æœ€åˆã®ãƒ†ã‚¹ãƒˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ã™ã€‚\",\n        \"äºŒç•ªç›®ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«ã¯ç•°ãªã‚‹å†…å®¹ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚\",\n        \"ä¸‰ç•ªç›®ã®ãƒ†ã‚­ã‚¹ãƒˆã¯æŠ€è¡“çš„ãªå†…å®¹ã«ã¤ã„ã¦èª¬æ˜ã—ã¦ã„ã¾ã™ã€‚\"\n    ]\n    \n    # Bedrock KBäº’æ›ãƒ™ã‚¯ãƒˆãƒ«åŸ‹ã‚è¾¼ã¿å‡¦ç†ã‚’ãƒ†ã‚¹ãƒˆ\n    processor = BedrockKBVectorProcessor()\n    \n    # åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ\n    result = processor.generate_embeddings(sample_texts)\n    print(f\"åŸ‹ã‚è¾¼ã¿ç”Ÿæˆçµæœ: {result.success}\")\n    print(f\"åŸ‹ã‚è¾¼ã¿æ•°: {len(result.embeddings)}\")\n    print(f\"åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒ: {len(result.embeddings[0]) if result.embeddings else 0}\")\n    \n    if result.success:\n        # Bedrock KBäº’æ›OpenSearchãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæˆ\n        chunks = [\n            {'content': text, 'metadata': {'chunk_index': i, 'chunk_type': 'paragraph'}}\n            for i, text in enumerate(sample_texts)\n        ]\n        \n        documents = processor.create_bedrock_kb_documents(\n            chunks=chunks,\n            embeddings=result.embeddings,\n            source_file=\"test_document.pdf\",\n            source_uri=\"\\\\file\\ishida\\éƒ¨ç½²\\directory\\test_document.pdf\",\n            author=\"user@example.com\",\n            file_size=1495625,\n            parent_chunks=[\"è¦ªãƒãƒ£ãƒ³ã‚¯1\", \"è¦ªãƒãƒ£ãƒ³ã‚¯2\", \"è¦ªãƒãƒ£ãƒ³ã‚¯3\"]\n        )\n        \n        print(f\"Bedrock KBäº’æ›OpenSearchãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {len(documents)}\")\n        \n        # OpenSearchã«æ ¼ç´\n        storage_result = processor.store_embeddings_to_opensearch(documents)\n        print(f\"æ ¼ç´çµæœ: {storage_result}\")\n        \n        # é¡ä¼¼æ¤œç´¢ãƒ†ã‚¹ãƒˆ\n        if result.embeddings:\n            search_result = processor.search_similar_documents(\n                query_embedding=result.embeddings[0],\n                k=3\n            )\n            print(f\"æ¤œç´¢çµæœ: {search_result}\")\n\n\nif __name__ == \"__main__\":\n    test_bedrock_kb_vector_embedding()\n"