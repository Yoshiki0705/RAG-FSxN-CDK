"""
メタデータ管理機能\n元ファイル情報、変換情報、処理履歴、パフォーマンス情報の包括的管理\n\"\"\"\n\nimport json\nimport logging\nimport os\nfrom typing import Dict, List, Any, Optional, Tuple\nfrom dataclasses import dataclass, asdict\nimport boto3\nfrom botocore.exceptions import ClientError\nimport hashlib\nfrom datetime import datetime, timedelta\nimport uuid\n\nlogger = logging.getLogger(__name__)\n\n@dataclass\nclass FileMetadata:\n    \"\"\"ファイルメタデータ\"\"\"\n    file_id: str\n    original_name: str\n    file_size: int\n    file_format: str\n    mime_type: Optional[str]\n    upload_timestamp: str\n    file_hash: str\n    s3_bucket: Optional[str] = None\n    s3_key: Optional[str] = None\n    user_id: Optional[str] = None\n    project_id: Optional[str] = None\n    \n@dataclass\nclass ProcessingMetadata:\n    \"\"\"処理メタデータ\"\"\"\n    processing_id: str\n    file_id: str\n    processing_strategy: str\n    attempted_methods: List[Dict[str, Any]]\n    final_method: str\n    processing_start_time: str\n    processing_end_time: str\n    total_processing_time: float\n    success: bool\n    error_message: Optional[str] = None\n    \n@dataclass\nclass ConversionMetadata:\n    \"\"\"変換メタデータ\"\"\"\n    conversion_id: str\n    processing_id: str\n    method: str  # 'markitdown' or 'langchain'\n    input_size: int\n    output_size: int\n    conversion_time: float\n    quality_score: Optional[float]\n    success: bool\n    error_details: Optional[Dict[str, Any]] = None\n    \n@dataclass\nclass ChunkingMetadata:\n    \"\"\"チャンキングメタデータ\"\"\"\n    chunking_id: str\n    processing_id: str\n    total_chunks: int\n    chunk_size: int\n    chunk_overlap: int\n    chunking_strategy: str\n    chunking_time: float\n    average_chunk_size: float\n    \n@dataclass\nclass EmbeddingMetadata:\n    \"\"\"埋め込みメタデータ\"\"\"\n    embedding_id: str\n    processing_id: str\n    embedding_model: str\n    embedding_dimension: int\n    total_embeddings: int\n    embedding_time: float\n    batch_size: int\n    average_embedding_time: float\n    \n@dataclass\nclass StorageMetadata:\n    \"\"\"格納メタデータ\"\"\"\n    storage_id: str\n    processing_id: str\n    storage_type: str  # 'opensearch', 'dynamodb', 's3'\n    stored_documents: int\n    storage_time: float\n    index_name: Optional[str] = None\n    table_name: Optional[str] = None\n    bucket_name: Optional[str] = None\n    \nclass MetadataManager:\n    \"\"\"メタデータ管理クラス\"\"\"\n    \n    def __init__(self, \n                 region: str = 'us-east-1',\n                 metadata_table: str = 'DocumentProcessingMetadata',\n                 tracking_table: str = 'EmbeddingProcessingTracking'):\n        \"\"\"\n        初期化\n        \n        Args:\n            region: AWSリージョン\n            metadata_table: メタデータテーブル名\n            tracking_table: 追跡テーブル名\n        \"\"\"\n        self.region = region\n        self.metadata_table_name = metadata_table\n        self.tracking_table_name = tracking_table\n        \n        # DynamoDB初期化\n        self.dynamodb = boto3.resource('dynamodb', region_name=region)\n        \n        try:\n            self.metadata_table = self.dynamodb.Table(metadata_table)\n            self.tracking_table = self.dynamodb.Table(tracking_table)\n            logger.info(f\"メタデータ管理を初期化: {metadata_table}, {tracking_table}\")\n        except Exception as e:\n            logger.error(f\"DynamoDBテーブル初期化エラー: {e}\")\n            self.metadata_table = None\n            self.tracking_table = None\n    \n    def create_file_metadata(self, \n                           file_name: str,\n                           file_content: bytes,\n                           file_format: str,\n                           mime_type: Optional[str] = None,\n                           user_id: Optional[str] = None,\n                           project_id: Optional[str] = None,\n                           s3_bucket: Optional[str] = None,\n                           s3_key: Optional[str] = None) -> FileMetadata:\n        \"\"\"\n        ファイルメタデータを作成\n        \n        Args:\n            file_name: ファイル名\n            file_content: ファイル内容\n            file_format: ファイル形式\n            mime_type: MIMEタイプ\n            user_id: ユーザーID\n            project_id: プロジェクトID\n            s3_bucket: S3バケット名\n            s3_key: S3キー\n            \n        Returns:\n            FileMetadata: ファイルメタデータ\n        \"\"\"\n        file_id = str(uuid.uuid4())\n        file_hash = hashlib.sha256(file_content).hexdigest()\n        \n        metadata = FileMetadata(\n            file_id=file_id,\n            original_name=file_name,\n            file_size=len(file_content),\n            file_format=file_format,\n            mime_type=mime_type,\n            upload_timestamp=datetime.utcnow().isoformat(),\n            file_hash=file_hash,\n            s3_bucket=s3_bucket,\n            s3_key=s3_key,\n            user_id=user_id,\n            project_id=project_id\n        )\n        \n        # DynamoDBに保存\n        self._save_file_metadata(metadata)\n        \n        logger.info(f\"ファイルメタデータ作成: {file_id} ({file_name})\")\n        return metadata\n    \n    def create_processing_metadata(self,\n                                 file_id: str,\n                                 processing_strategy: str) -> ProcessingMetadata:\n        \"\"\"\n        処理メタデータを作成\n        \n        Args:\n            file_id: ファイルID\n            processing_strategy: 処理戦略\n            \n        Returns:\n            ProcessingMetadata: 処理メタデータ\n        \"\"\"\n        processing_id = str(uuid.uuid4())\n        \n        metadata = ProcessingMetadata(\n            processing_id=processing_id,\n            file_id=file_id,\n            processing_strategy=processing_strategy,\n            attempted_methods=[],\n            final_method='',\n            processing_start_time=datetime.utcnow().isoformat(),\n            processing_end_time='',\n            total_processing_time=0.0,\n            success=False\n        )\n        \n        logger.info(f\"処理メタデータ作成: {processing_id} (ファイル: {file_id})\")\n        return metadata\n    \n    def update_processing_metadata(self,\n                                 processing_metadata: ProcessingMetadata,\n                                 attempted_methods: List[Dict[str, Any]],\n                                 final_method: str,\n                                 success: bool,\n                                 error_message: Optional[str] = None) -> ProcessingMetadata:\n        \"\"\"\n        処理メタデータを更新\n        \n        Args:\n            processing_metadata: 処理メタデータ\n            attempted_methods: 試行された方法リスト\n            final_method: 最終的な方法\n            success: 成功フラグ\n            error_message: エラーメッセージ\n            \n        Returns:\n            ProcessingMetadata: 更新された処理メタデータ\n        \"\"\"\n        end_time = datetime.utcnow().isoformat()\n        start_time = datetime.fromisoformat(processing_metadata.processing_start_time.replace('Z', '+00:00'))\n        end_time_dt = datetime.fromisoformat(end_time.replace('Z', '+00:00'))\n        total_time = (end_time_dt - start_time).total_seconds() * 1000  # ミリ秒\n        \n        processing_metadata.attempted_methods = attempted_methods\n        processing_metadata.final_method = final_method\n        processing_metadata.processing_end_time = end_time\n        processing_metadata.total_processing_time = total_time\n        processing_metadata.success = success\n        processing_metadata.error_message = error_message\n        \n        # DynamoDBに保存\n        self._save_processing_metadata(processing_metadata)\n        \n        logger.info(f\"処理メタデータ更新: {processing_metadata.processing_id} (成功: {success})\")\n        return processing_metadata\n    \n    def create_conversion_metadata(self,\n                                 processing_id: str,\n                                 method: str,\n                                 input_size: int,\n                                 output_size: int,\n                                 conversion_time: float,\n                                 quality_score: Optional[float] = None,\n                                 success: bool = True,\n                                 error_details: Optional[Dict[str, Any]] = None) -> ConversionMetadata:\n        \"\"\"\n        変換メタデータを作成\n        \n        Args:\n            processing_id: 処理ID\n            method: 変換方法\n            input_size: 入力サイズ\n            output_size: 出力サイズ\n            conversion_time: 変換時間\n            quality_score: 品質スコア\n            success: 成功フラグ\n            error_details: エラー詳細\n            \n        Returns:\n            ConversionMetadata: 変換メタデータ\n        \"\"\"\n        conversion_id = str(uuid.uuid4())\n        \n        metadata = ConversionMetadata(\n            conversion_id=conversion_id,\n            processing_id=processing_id,\n            method=method,\n            input_size=input_size,\n            output_size=output_size,\n            conversion_time=conversion_time,\n            quality_score=quality_score,\n            success=success,\n            error_details=error_details\n        )\n        \n        # DynamoDBに保存\n        self._save_conversion_metadata(metadata)\n        \n        logger.info(f\"変換メタデータ作成: {conversion_id} ({method})\")\n        return metadata\n    \n    def create_chunking_metadata(self,\n                               processing_id: str,\n                               total_chunks: int,\n                               chunk_size: int,\n                               chunk_overlap: int,\n                               chunking_strategy: str,\n                               chunking_time: float,\n                               average_chunk_size: float) -> ChunkingMetadata:\n        \"\"\"\n        チャンキングメタデータを作成\n        \n        Args:\n            processing_id: 処理ID\n            total_chunks: 総チャンク数\n            chunk_size: チャンクサイズ\n            chunk_overlap: チャンクオーバーラップ\n            chunking_strategy: チャンキング戦略\n            chunking_time: チャンキング時間\n            average_chunk_size: 平均チャンクサイズ\n            \n        Returns:\n            ChunkingMetadata: チャンキングメタデータ\n        \"\"\"\n        chunking_id = str(uuid.uuid4())\n        \n        metadata = ChunkingMetadata(\n            chunking_id=chunking_id,\n            processing_id=processing_id,\n            total_chunks=total_chunks,\n            chunk_size=chunk_size,\n            chunk_overlap=chunk_overlap,\n            chunking_strategy=chunking_strategy,\n            chunking_time=chunking_time,\n            average_chunk_size=average_chunk_size\n        )\n        \n        # DynamoDBに保存\n        self._save_chunking_metadata(metadata)\n        \n        logger.info(f\"チャンキングメタデータ作成: {chunking_id} ({total_chunks}チャンク)\")\n        return metadata\n    \n    def create_embedding_metadata(self,\n                                processing_id: str,\n                                embedding_model: str,\n                                embedding_dimension: int,\n                                total_embeddings: int,\n                                embedding_time: float,\n                                batch_size: int,\n                                average_embedding_time: float) -> EmbeddingMetadata:\n        \"\"\"\n        埋め込みメタデータを作成\n        \n        Args:\n            processing_id: 処理ID\n            embedding_model: 埋め込みモデル\n            embedding_dimension: 埋め込み次元\n            total_embeddings: 総埋め込み数\n            embedding_time: 埋め込み時間\n            batch_size: バッチサイズ\n            average_embedding_time: 平均埋め込み時間\n            \n        Returns:\n            EmbeddingMetadata: 埋め込みメタデータ\n        \"\"\"\n        embedding_id = str(uuid.uuid4())\n        \n        metadata = EmbeddingMetadata(\n            embedding_id=embedding_id,\n            processing_id=processing_id,\n            embedding_model=embedding_model,\n            embedding_dimension=embedding_dimension,\n            total_embeddings=total_embeddings,\n            embedding_time=embedding_time,\n            batch_size=batch_size,\n            average_embedding_time=average_embedding_time\n        )\n        \n        # DynamoDBに保存\n        self._save_embedding_metadata(metadata)\n        \n        logger.info(f\"埋め込みメタデータ作成: {embedding_id} ({total_embeddings}埋め込み)\")\n        return metadata\n    \n    def create_storage_metadata(self,\n                              processing_id: str,\n                              storage_type: str,\n                              stored_documents: int,\n                              storage_time: float,\n                              index_name: Optional[str] = None,\n                              table_name: Optional[str] = None,\n                              bucket_name: Optional[str] = None) -> StorageMetadata:\n        \"\"\"\n        格納メタデータを作成\n        \n        Args:\n            processing_id: 処理ID\n            storage_type: 格納タイプ\n            stored_documents: 格納ドキュメント数\n            storage_time: 格納時間\n            index_name: インデックス名\n            table_name: テーブル名\n            bucket_name: バケット名\n            \n        Returns:\n            StorageMetadata: 格納メタデータ\n        \"\"\"\n        storage_id = str(uuid.uuid4())\n        \n        metadata = StorageMetadata(\n            storage_id=storage_id,\n            processing_id=processing_id,\n            storage_type=storage_type,\n            stored_documents=stored_documents,\n            storage_time=storage_time,\n            index_name=index_name,\n            table_name=table_name,\n            bucket_name=bucket_name\n        )\n        \n        # DynamoDBに保存\n        self._save_storage_metadata(metadata)\n        \n        logger.info(f\"格納メタデータ作成: {storage_id} ({storage_type}, {stored_documents}ドキュメント)\")\n        return metadata\n    \n    def get_processing_history(self, \n                             file_id: Optional[str] = None,\n                             user_id: Optional[str] = None,\n                             project_id: Optional[str] = None,\n                             limit: int = 100) -> List[Dict[str, Any]]:\n        \"\"\"\n        処理履歴を取得\n        \n        Args:\n            file_id: ファイルID\n            user_id: ユーザーID\n            project_id: プロジェクトID\n            limit: 取得制限数\n            \n        Returns:\n            List[Dict]: 処理履歴リスト\n        \"\"\"\n        try:\n            if not self.metadata_table:\n                logger.warning(\"メタデータテーブルが利用できません\")\n                return []\n            \n            # クエリ条件を構築\n            filter_expression = None\n            expression_attribute_values = {}\n            \n            if file_id:\n                filter_expression = \"file_id = :file_id\"\n                expression_attribute_values[\":file_id\"] = file_id\n            \n            if user_id:\n                if filter_expression:\n                    filter_expression += \" AND user_id = :user_id\"\n                else:\n                    filter_expression = \"user_id = :user_id\"\n                expression_attribute_values[\":user_id\"] = user_id\n            \n            if project_id:\n                if filter_expression:\n                    filter_expression += \" AND project_id = :project_id\"\n                else:\n                    filter_expression = \"project_id = :project_id\"\n                expression_attribute_values[\":project_id\"] = project_id\n            \n            # スキャン実行\n            scan_kwargs = {\n                'Limit': limit\n            }\n            \n            if filter_expression:\n                scan_kwargs['FilterExpression'] = filter_expression\n                scan_kwargs['ExpressionAttributeValues'] = expression_attribute_values\n            \n            response = self.metadata_table.scan(**scan_kwargs)\n            \n            logger.info(f\"処理履歴取得: {len(response['Items'])}件\")\n            return response['Items']\n            \n        except Exception as e:\n            logger.error(f\"処理履歴取得エラー: {e}\")\n            return []\n    \n    def get_performance_statistics(self, \n                                 days: int = 30) -> Dict[str, Any]:\n        \"\"\"\n        パフォーマンス統計を取得\n        \n        Args:\n            days: 統計期間（日数）\n            \n        Returns:\n            Dict: パフォーマンス統計\n        \"\"\"\n        try:\n            if not self.metadata_table:\n                logger.warning(\"メタデータテーブルが利用できません\")\n                return {}\n            \n            # 期間フィルター\n            start_date = (datetime.utcnow() - timedelta(days=days)).isoformat()\n            \n            response = self.metadata_table.scan(\n                FilterExpression=\"processing_start_time >= :start_date\",\n                ExpressionAttributeValues={\n                    \":start_date\": start_date\n                }\n            )\n            \n            items = response['Items']\n            \n            # 統計計算\n            total_processed = len(items)\n            successful = len([item for item in items if item.get('success', False)])\n            failed = total_processed - successful\n            \n            processing_times = [float(item.get('total_processing_time', 0)) for item in items if item.get('total_processing_time')]\n            avg_processing_time = sum(processing_times) / len(processing_times) if processing_times else 0\n            \n            # 方法別統計\n            method_stats = {}\n            for item in items:\n                method = item.get('final_method', 'unknown')\n                if method not in method_stats:\n                    method_stats[method] = {'count': 0, 'success': 0}\n                method_stats[method]['count'] += 1\n                if item.get('success', False):\n                    method_stats[method]['success'] += 1\n            \n            statistics = {\n                'period_days': days,\n                'total_processed': total_processed,\n                'successful': successful,\n                'failed': failed,\n                'success_rate': (successful / total_processed * 100) if total_processed > 0 else 0,\n                'average_processing_time_ms': avg_processing_time,\n                'method_statistics': method_stats,\n                'generated_at': datetime.utcnow().isoformat()\n            }\n            \n            logger.info(f\"パフォーマンス統計生成: {total_processed}件処理, 成功率{statistics['success_rate']:.1f}%\")\n            return statistics\n            \n        except Exception as e:\n            logger.error(f\"パフォーマンス統計取得エラー: {e}\")\n            return {}\n    \n    def _save_file_metadata(self, metadata: FileMetadata):\n        \"\"\"ファイルメタデータをDynamoDBに保存\"\"\"\n        if not self.metadata_table:\n            return\n        \n        try:\n            item = asdict(metadata)\n            item['record_type'] = 'file_metadata'\n            item['ttl'] = int((datetime.utcnow() + timedelta(days=365)).timestamp())\n            \n            self.metadata_table.put_item(Item=item)\n        except Exception as e:\n            logger.error(f\"ファイルメタデータ保存エラー: {e}\")\n    \n    def _save_processing_metadata(self, metadata: ProcessingMetadata):\n        \"\"\"処理メタデータをDynamoDBに保存\"\"\"\n        if not self.metadata_table:\n            return\n        \n        try:\n            item = asdict(metadata)\n            item['record_type'] = 'processing_metadata'\n            item['ttl'] = int((datetime.utcnow() + timedelta(days=90)).timestamp())\n            \n            self.metadata_table.put_item(Item=item)\n        except Exception as e:\n            logger.error(f\"処理メタデータ保存エラー: {e}\")\n    \n    def _save_conversion_metadata(self, metadata: ConversionMetadata):\n        \"\"\"変換メタデータをDynamoDBに保存\"\"\"\n        if not self.metadata_table:\n            return\n        \n        try:\n            item = asdict(metadata)\n            item['record_type'] = 'conversion_metadata'\n            item['ttl'] = int((datetime.utcnow() + timedelta(days=90)).timestamp())\n            \n            self.metadata_table.put_item(Item=item)\n        except Exception as e:\n            logger.error(f\"変換メタデータ保存エラー: {e}\")\n    \n    def _save_chunking_metadata(self, metadata: ChunkingMetadata):\n        \"\"\"チャンキングメタデータをDynamoDBに保存\"\"\"\n        if not self.metadata_table:\n            return\n        \n        try:\n            item = asdict(metadata)\n            item['record_type'] = 'chunking_metadata'\n            item['ttl'] = int((datetime.utcnow() + timedelta(days=90)).timestamp())\n            \n            self.metadata_table.put_item(Item=item)\n        except Exception as e:\n            logger.error(f\"チャンキングメタデータ保存エラー: {e}\")\n    \n    def _save_embedding_metadata(self, metadata: EmbeddingMetadata):\n        \"\"\"埋め込みメタデータをDynamoDBに保存\"\"\"\n        if not self.metadata_table:\n            return\n        \n        try:\n            item = asdict(metadata)\n            item['record_type'] = 'embedding_metadata'\n            item['ttl'] = int((datetime.utcnow() + timedelta(days=90)).timestamp())\n            \n            self.metadata_table.put_item(Item=item)\n        except Exception as e:\n            logger.error(f\"埋め込みメタデータ保存エラー: {e}\")\n    \n    def _save_storage_metadata(self, metadata: StorageMetadata):\n        \"\"\"格納メタデータをDynamoDBに保存\"\"\"\n        if not self.metadata_table:\n            return\n        \n        try:\n            item = asdict(metadata)\n            item['record_type'] = 'storage_metadata'\n            item['ttl'] = int((datetime.utcnow() + timedelta(days=90)).timestamp())\n            \n            self.metadata_table.put_item(Item=item)\n        except Exception as e:\n            logger.error(f\"格納メタデータ保存エラー: {e}\")\n\n\ndef create_metadata_manager(config: Dict[str, Any]) -> MetadataManager:\n    \"\"\"\n    メタデータ管理インスタンスを作成\n    \n    Args:\n        config: 設定辞書\n        \n    Returns:\n        MetadataManager: メタデータ管理インスタンス\n    \"\"\"\n    return MetadataManager(\n        region=config.get('region', 'us-east-1'),\n        metadata_table=config.get('metadata_table', 'DocumentProcessingMetadata'),\n        tracking_table=config.get('tracking_table', 'EmbeddingProcessingTracking')\n    )\n\n\n# テスト用のサンプル関数\ndef test_metadata_manager():\n    \"\"\"\n    メタデータ管理のテスト\n    \"\"\"\n    # メタデータ管理をテスト\n    manager = MetadataManager()\n    \n    # ファイルメタデータ作成\n    file_metadata = manager.create_file_metadata(\n        file_name=\"test_document.pdf\",\n        file_content=b\"test content\",\n        file_format=\"pdf\",\n        mime_type=\"application/pdf\",\n        user_id=\"test_user\",\n        project_id=\"test_project\"\n    )\n    \n    print(f\"ファイルメタデータ: {file_metadata.file_id}\")\n    \n    # 処理メタデータ作成\n    processing_metadata = manager.create_processing_metadata(\n        file_id=file_metadata.file_id,\n        processing_strategy=\"markitdown-first\"\n    )\n    \n    print(f\"処理メタデータ: {processing_metadata.processing_id}\")\n    \n    # 変換メタデータ作成\n    conversion_metadata = manager.create_conversion_metadata(\n        processing_id=processing_metadata.processing_id,\n        method=\"markitdown\",\n        input_size=1000,\n        output_size=1500,\n        conversion_time=250.5,\n        quality_score=85.0\n    )\n    \n    print(f\"変換メタデータ: {conversion_metadata.conversion_id}\")\n    \n    # 処理完了\n    manager.update_processing_metadata(\n        processing_metadata=processing_metadata,\n        attempted_methods=[{\"method\": \"markitdown\", \"success\": True}],\n        final_method=\"markitdown\",\n        success=True\n    )\n    \n    print(\"メタデータ管理テスト完了\")\n\n\nif __name__ == \"__main__\":\n    test_metadata_manager()\n"